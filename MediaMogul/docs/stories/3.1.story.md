# Story 3.1: Migration Planning Foundation

## Story

As a user,
I want a comprehensive migration planning system,
So that I can analyze my data, understand migration requirements, create detailed migration plans, and execute them safely with full visibility into the process.

## Story Context

**Epic:** 3 - Migration Planning and Execution  
**Dependencies:** Epic 2 Complete (Task Engine, MD5, MediaInfo, UI, Opportunistic Logic)  
**Story Type:** Core Feature - Migration Planning  

This story establishes the foundation for MediaMogul's primary value proposition: intelligent data migration planning. It builds upon the task engine infrastructure from Epic 2 to provide comprehensive analysis, planning, and execution capabilities. This fulfills the core PRD goal of "intelligent, user-friendly data migration and organization system."

## Acceptance Criteria

### Migration Plan Creation & Management
- [ ] **Plan creation wizard:** Step-by-step interface for creating new migration plans
- [ ] **Plan templates:** Pre-configured templates for common migration scenarios
- [ ] **Plan persistence:** Save, load, and modify migration plans with versioning
- [ ] **Plan validation:** Validate plan feasibility before execution (space, permissions, conflicts)
- [ ] **Plan comparison:** Compare different migration scenarios and their impacts
- [ ] **Plan naming:** User-friendly naming with descriptions and metadata

### Source Data Analysis
- [ ] **Comprehensive scanning:** Analyze source disks/paths for file types, sizes, duplicates
- [ ] **Duplicate detection:** Identify duplicate files using MD5 checksums across all sources
- [ ] **Media analysis:** Extract media metadata and categorize files by type/quality
- [ ] **Space analysis:** Calculate total size, largest files, directory structure depth
- [ ] **File age analysis:** Identify old/recent files, modification patterns
- [ ] **Risk assessment:** Identify potentially problematic files (large, corrupt, permissions)

### Destination Planning
- [ ] **Destination configuration:** Configure target disks/paths with capacity validation
- [ ] **Space planning:** Ensure adequate space with safety margins
- [ ] **Directory structure:** Plan destination directory organization and naming
- [ ] **Conflict resolution:** Plan handling of filename conflicts and duplicate files
- [ ] **Permission planning:** Plan file/directory permissions and ownership
- [ ] **Backup strategy:** Plan backup approach for existing destination files

### Migration Strategy Definition
- [ ] **File organization rules:** Define how files should be organized (by type, date, size)
- [ ] **Duplicate handling:** Define policy for duplicate files (keep, skip, rename)
- [ ] **Large file strategy:** Special handling for files above size threshold
- [ ] **Media organization:** Organize media files by metadata (year, resolution, format)
- [ ] **Batch planning:** Break migration into manageable batches with dependencies
- [ ] **Rollback planning:** Plan rollback strategy for failed migrations

### Impact Analysis & Reporting
- [ ] **Migration preview:** Detailed preview of planned changes before execution
- [ ] **Impact assessment:** Analysis of time, space, and resource requirements
- [ ] **Risk analysis:** Identify potential issues and mitigation strategies
- [ ] **Progress estimation:** Estimate migration duration based on file sizes and disk speeds
- [ ] **Resource planning:** Estimate CPU, memory, and I/O requirements
- [ ] **Detailed reporting:** Generate comprehensive migration plan reports

### Plan Execution Preparation
- [ ] **Pre-execution validation:** Final validation before migration starts
- [ ] **Task generation:** Convert migration plan into task engine jobs
- [ ] **Dependency mapping:** Ensure proper task sequencing and dependencies
- [ ] **Resource allocation:** Plan worker allocation and execution priority
- [ ] **Monitoring setup:** Prepare progress tracking and error handling
- [ ] **User confirmation:** Clear confirmation dialog with plan summary

## Technical Implementation

### Backend Components

**Migration Plan Model** (`internal/models/migration_plan.go`)
```go
type MigrationPlan struct {
    ID              string                `json:"id" db:"id"`
    Name            string                `json:"name" db:"name"`
    Description     string                `json:"description" db:"description"`
    Status          MigrationPlanStatus   `json:"status" db:"status"`
    SourceConfig    SourceConfiguration   `json:"source_config" db:"source_config"`
    DestConfig      DestConfiguration     `json:"dest_config" db:"dest_config"`
    Strategy        MigrationStrategy     `json:"strategy" db:"strategy"`
    Analysis        PlanAnalysis          `json:"analysis" db:"analysis"`
    CreatedOn       int64                 `json:"created_on" db:"created_on"`
    UpdatedOn       int64                 `json:"updated_on" db:"updated_on"`
    LastExecutedOn  *int64                `json:"last_executed_on,omitempty" db:"last_executed_on"`
    Version         int                   `json:"version" db:"version"`
}

type MigrationPlanStatus string
const (
    PlanStatusDraft     MigrationPlanStatus = "draft"
    PlanStatusAnalyzing MigrationPlanStatus = "analyzing"
    PlanStatusReady     MigrationPlanStatus = "ready"
    PlanStatusExecuting MigrationPlanStatus = "executing"
    PlanStatusComplete  MigrationPlanStatus = "complete"
    PlanStatusFailed    MigrationPlanStatus = "failed"
)

type SourceConfiguration struct {
    Disks           []string              `json:"disks"`
    Paths           []string              `json:"paths"`
    IncludePatterns []string              `json:"include_patterns"`
    ExcludePatterns []string              `json:"exclude_patterns"`
    MinFileSize     int64                 `json:"min_file_size"`
    MaxFileSize     int64                 `json:"max_file_size"`
    FileTypes       []string              `json:"file_types"`
}

type DestConfiguration struct {
    TargetDisk      string                `json:"target_disk"`
    BasePath        string                `json:"base_path"`
    DirectoryStructure DirectoryStructure `json:"directory_structure"`
    NamingRules     []NamingRule          `json:"naming_rules"`
    SpaceReservation int64                `json:"space_reservation"`
}

type MigrationStrategy struct {
    DuplicateHandling  DuplicateStrategy   `json:"duplicate_handling"`
    ConflictResolution ConflictStrategy    `json:"conflict_resolution"`
    OrganizationRules  []OrganizationRule  `json:"organization_rules"`
    BatchSize          int                 `json:"batch_size"`
    ParallelTasks      int                 `json:"parallel_tasks"`
    LargeFileThreshold int64               `json:"large_file_threshold"`
    BackupStrategy     BackupStrategy      `json:"backup_strategy"`
}

type PlanAnalysis struct {
    SourceAnalysis     SourceAnalysis      `json:"source_analysis"`
    DuplicateAnalysis  DuplicateAnalysis   `json:"duplicate_analysis"`
    SpaceAnalysis      SpaceAnalysis       `json:"space_analysis"`
    RiskAnalysis       []RiskItem          `json:"risk_analysis"`
    EstimatedDuration  int64               `json:"estimated_duration"`
    ResourceRequirements ResourceEstimate  `json:"resource_requirements"`
    AnalyzedOn         int64               `json:"analyzed_on"`
}
```

**Migration Planning Service** (`internal/services/migration_planner.go`)
```go
type MigrationPlannerService struct {
    db            *database.DB
    fileService   *FileService
    taskService   *TaskService
    diskService   *DiskService
    logger        *slog.Logger
}

func NewMigrationPlannerService(deps ServiceDependencies) *MigrationPlannerService {
    return &MigrationPlannerService{
        db:          deps.DB,
        fileService: deps.FileService,
        taskService: deps.TaskService,
        diskService: deps.DiskService,
        logger:      deps.Logger.With("service", "migration_planner"),
    }
}

// CreatePlan creates a new migration plan
func (s *MigrationPlannerService) CreatePlan(ctx context.Context, req CreatePlanRequest) (*MigrationPlan, error) {
    plan := &MigrationPlan{
        ID:           generatePlanID(),
        Name:         req.Name,
        Description:  req.Description,
        Status:       PlanStatusDraft,
        SourceConfig: req.SourceConfig,
        DestConfig:   req.DestConfig,
        Strategy:     req.Strategy,
        CreatedOn:    time.Now().Unix(),
        UpdatedOn:    time.Now().Unix(),
        Version:      1,
    }
    
    if err := s.validatePlan(ctx, plan); err != nil {
        return nil, fmt.Errorf("plan validation failed: %w", err)
    }
    
    if err := s.savePlan(ctx, plan); err != nil {
        return nil, fmt.Errorf("failed to save plan: %w", err)
    }
    
    s.logger.Info("Migration plan created", "plan_id", plan.ID, "name", plan.Name)
    return plan, nil
}

// AnalyzePlan performs comprehensive analysis of a migration plan
func (s *MigrationPlannerService) AnalyzePlan(ctx context.Context, planID string) (*PlanAnalysis, error) {
    plan, err := s.GetPlan(ctx, planID)
    if err != nil {
        return nil, err
    }
    
    plan.Status = PlanStatusAnalyzing
    s.savePlan(ctx, plan)
    
    // Perform parallel analysis
    var wg sync.WaitGroup
    var analysis PlanAnalysis
    var analysisErr error
    
    // Source analysis
    wg.Add(1)
    go func() {
        defer wg.Done()
        sourceAnalysis, err := s.analyzeSourceData(ctx, plan.SourceConfig)
        if err != nil {
            analysisErr = err
            return
        }
        analysis.SourceAnalysis = sourceAnalysis
    }()
    
    // Duplicate analysis
    wg.Add(1)
    go func() {
        defer wg.Done()
        duplicateAnalysis, err := s.analyzeDuplicates(ctx, plan.SourceConfig)
        if err != nil {
            analysisErr = err
            return
        }
        analysis.DuplicateAnalysis = duplicateAnalysis
    }()
    
    // Space analysis
    wg.Add(1)
    go func() {
        defer wg.Done()
        spaceAnalysis, err := s.analyzeSpaceRequirements(ctx, plan)
        if err != nil {
            analysisErr = err
            return
        }
        analysis.SpaceAnalysis = spaceAnalysis
    }()
    
    // Risk analysis
    wg.Add(1)
    go func() {
        defer wg.Done()
        riskAnalysis, err := s.analyzeRisks(ctx, plan)
        if err != nil {
            analysisErr = err
            return
        }
        analysis.RiskAnalysis = riskAnalysis
    }()
    
    wg.Wait()
    
    if analysisErr != nil {
        plan.Status = PlanStatusDraft
        s.savePlan(ctx, plan)
        return nil, fmt.Errorf("analysis failed: %w", analysisErr)
    }
    
    // Calculate estimates
    analysis.EstimatedDuration = s.estimateDuration(analysis)
    analysis.ResourceRequirements = s.estimateResources(analysis)
    analysis.AnalyzedOn = time.Now().Unix()
    
    // Update plan
    plan.Analysis = analysis
    plan.Status = PlanStatusReady
    plan.UpdatedOn = time.Now().Unix()
    s.savePlan(ctx, plan)
    
    s.logger.Info("Plan analysis completed", "plan_id", planID, "duration_estimate", analysis.EstimatedDuration)
    return &analysis, nil
}

// GenerateTasks converts migration plan into executable tasks
func (s *MigrationPlannerService) GenerateTasks(ctx context.Context, planID string) ([]Task, error) {
    plan, err := s.GetPlan(ctx, planID)
    if err != nil {
        return nil, err
    }
    
    if plan.Status != PlanStatusReady {
        return nil, fmt.Errorf("plan must be analyzed before generating tasks")
    }
    
    var tasks []Task
    
    // Generate file organization tasks
    orgTasks, err := s.generateOrganizationTasks(ctx, plan)
    if err != nil {
        return nil, err
    }
    tasks = append(tasks, orgTasks...)
    
    // Generate move/copy tasks
    moveTasks, err := s.generateMoveFileTasks(ctx, plan)
    if err != nil {
        return nil, err
    }
    tasks = append(tasks, moveTasks...)
    
    // Generate cleanup tasks
    cleanupTasks, err := s.generateCleanupTasks(ctx, plan)
    if err != nil {
        return nil, err
    }
    tasks = append(tasks, cleanupTasks...)
    
    // Generate verification tasks
    verificationTasks, err := s.generateVerificationTasks(ctx, plan)
    if err != nil {
        return nil, err
    }
    tasks = append(tasks, verificationTasks...)
    
    s.logger.Info("Generated tasks for migration plan", "plan_id", planID, "task_count", len(tasks))
    return tasks, nil
}
```

**Plan Analysis Components** (`internal/services/plan_analyzer.go`)
```go
func (s *MigrationPlannerService) analyzeSourceData(ctx context.Context, config SourceConfiguration) (SourceAnalysis, error) {
    var analysis SourceAnalysis
    
    // Collect all files matching criteria
    files, err := s.fileService.FindFiles(ctx, FileSearchCriteria{
        Disks:           config.Disks,
        Paths:           config.Paths,
        IncludePatterns: config.IncludePatterns,
        ExcludePatterns: config.ExcludePatterns,
        MinSize:         config.MinFileSize,
        MaxSize:         config.MaxFileSize,
        FileTypes:       config.FileTypes,
    })
    if err != nil {
        return analysis, err
    }
    
    // Analyze file distribution
    analysis.TotalFiles = len(files)
    analysis.TotalSize = 0
    analysis.FileTypes = make(map[string]int)
    analysis.SizeDistribution = make(map[string]int)
    
    for _, file := range files {
        analysis.TotalSize += file.Size
        
        // File type analysis
        ext := filepath.Ext(file.Name)
        analysis.FileTypes[ext]++
        
        // Size distribution
        if file.Size < 1*MB {
            analysis.SizeDistribution["small"]++
        } else if file.Size < 100*MB {
            analysis.SizeDistribution["medium"]++
        } else if file.Size < 1*GB {
            analysis.SizeDistribution["large"]++
        } else {
            analysis.SizeDistribution["huge"]++
        }
        
        // Track largest files
        if len(analysis.LargestFiles) < 10 {
            analysis.LargestFiles = append(analysis.LargestFiles, file)
        } else {
            // Replace smallest if current is larger
            smallestIdx := 0
            for i, f := range analysis.LargestFiles {
                if f.Size < analysis.LargestFiles[smallestIdx].Size {
                    smallestIdx = i
                }
            }
            if file.Size > analysis.LargestFiles[smallestIdx].Size {
                analysis.LargestFiles[smallestIdx] = file
            }
        }
    }
    
    return analysis, nil
}

func (s *MigrationPlannerService) analyzeDuplicates(ctx context.Context, config SourceConfiguration) (DuplicateAnalysis, error) {
    // Find all files with MD5 checksums
    files, err := s.fileService.GetFilesWithMD5(ctx, config.Disks)
    if err != nil {
        return DuplicateAnalysis{}, err
    }
    
    // Group by MD5 hash
    md5Groups := make(map[string][]File)
    for _, file := range files {
        if file.MD5Hash != nil {
            md5Groups[*file.MD5Hash] = append(md5Groups[*file.MD5Hash], file)
        }
    }
    
    var analysis DuplicateAnalysis
    analysis.TotalFiles = len(files)
    analysis.FilesWithMD5 = len(files)
    analysis.DuplicateGroups = []DuplicateGroup{}
    analysis.SpaceWastedByDuplicates = 0
    
    for hash, groupFiles := range md5Groups {
        if len(groupFiles) > 1 {
            group := DuplicateGroup{
                MD5Hash:       hash,
                Files:         groupFiles,
                FileCount:     len(groupFiles),
                TotalSize:     groupFiles[0].Size * int64(len(groupFiles)),
                WastedSpace:   groupFiles[0].Size * int64(len(groupFiles)-1),
            }
            analysis.DuplicateGroups = append(analysis.DuplicateGroups, group)
            analysis.SpaceWastedByDuplicates += group.WastedSpace
        }
    }
    
    analysis.DuplicateFiles = 0
    for _, group := range analysis.DuplicateGroups {
        analysis.DuplicateFiles += group.FileCount - 1 // Don't count the original
    }
    
    return analysis, nil
}
```

### API Endpoints

**Migration Plan Controller** (`internal/api/migration_plans.go`)
```go
// POST /api/v1/migration-plans
func (h *MigrationPlanHandler) CreatePlan(c *gin.Context) {
    var req CreatePlanRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": "Invalid request body", "details": err.Error()})
        return
    }
    
    plan, err := h.plannerService.CreatePlan(c.Request.Context(), req)
    if err != nil {
        h.logger.Error("Failed to create migration plan", "error", err)
        c.JSON(500, gin.H{"error": "Failed to create plan"})
        return
    }
    
    c.JSON(201, plan)
}

// GET /api/v1/migration-plans
func (h *MigrationPlanHandler) ListPlans(c *gin.Context) {
    plans, err := h.plannerService.ListPlans(c.Request.Context())
    if err != nil {
        h.logger.Error("Failed to list migration plans", "error", err)
        c.JSON(500, gin.H{"error": "Failed to list plans"})
        return
    }
    
    c.JSON(200, gin.H{"plans": plans})
}

// GET /api/v1/migration-plans/:id
func (h *MigrationPlanHandler) GetPlan(c *gin.Context) {
    planID := c.Param("id")
    plan, err := h.plannerService.GetPlan(c.Request.Context(), planID)
    if err != nil {
        if errors.Is(err, ErrPlanNotFound) {
            c.JSON(404, gin.H{"error": "Plan not found"})
            return
        }
        h.logger.Error("Failed to get migration plan", "plan_id", planID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to get plan"})
        return
    }
    
    c.JSON(200, plan)
}

// POST /api/v1/migration-plans/:id/analyze
func (h *MigrationPlanHandler) AnalyzePlan(c *gin.Context) {
    planID := c.Param("id")
    
    // Start analysis asynchronously
    go func() {
        analysis, err := h.plannerService.AnalyzePlan(context.Background(), planID)
        if err != nil {
            h.logger.Error("Plan analysis failed", "plan_id", planID, "error", err)
        } else {
            h.logger.Info("Plan analysis completed", "plan_id", planID, "files", analysis.SourceAnalysis.TotalFiles)
        }
    }()
    
    c.JSON(202, gin.H{"message": "Analysis started", "plan_id": planID})
}

// POST /api/v1/migration-plans/:id/execute
func (h *MigrationPlanHandler) ExecutePlan(c *gin.Context) {
    planID := c.Param("id")
    
    tasks, err := h.plannerService.GenerateTasks(c.Request.Context(), planID)
    if err != nil {
        h.logger.Error("Failed to generate tasks", "plan_id", planID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to generate tasks"})
        return
    }
    
    // Submit tasks to task engine
    for _, task := range tasks {
        if err := h.taskService.SubmitTask(c.Request.Context(), task); err != nil {
            h.logger.Error("Failed to submit task", "task_id", task.UID, "error", err)
            c.JSON(500, gin.H{"error": "Failed to submit tasks"})
            return
        }
    }
    
    // Update plan status
    if err := h.plannerService.UpdatePlanStatus(c.Request.Context(), planID, PlanStatusExecuting); err != nil {
        h.logger.Error("Failed to update plan status", "plan_id", planID, "error", err)
    }
    
    c.JSON(200, gin.H{"message": "Migration started", "plan_id": planID, "tasks_created": len(tasks)})
}
```

### Frontend Components

**Migration Plans Page** (`app/migration/page.tsx`)
```tsx
'use client'
import { useState, useEffect } from 'react'
import { useMigrationPlans } from '@/hooks/useMigrationPlans'
import { PlanList } from '@/components/migration/PlanList'
import { CreatePlanDialog } from '@/components/migration/CreatePlanDialog'
import { PlanDetailsModal } from '@/components/migration/PlanDetailsModal'

export default function MigrationPlansPage() {
  const { plans, isLoading, createPlan, analyzePlan, executePlan } = useMigrationPlans()
  const [isCreateDialogOpen, setIsCreateDialogOpen] = useState(false)
  const [selectedPlanId, setSelectedPlanId] = useState<string | null>(null)
  
  return (
    <div className="migration-plans-container">
      <div className="page-header">
        <h1>Migration Plans</h1>
        <Button 
          onClick={() => setIsCreateDialogOpen(true)}
          className="create-plan-button"
        >
          Create New Plan
        </Button>
      </div>
      
      <PlanList 
        plans={plans}
        isLoading={isLoading}
        onPlanSelect={setSelectedPlanId}
        onAnalyzePlan={analyzePlan}
        onExecutePlan={executePlan}
      />
      
      <CreatePlanDialog
        isOpen={isCreateDialogOpen}
        onClose={() => setIsCreateDialogOpen(false)}
        onCreatePlan={createPlan}
      />
      
      {selectedPlanId && (
        <PlanDetailsModal
          planId={selectedPlanId}
          isOpen={!!selectedPlanId}
          onClose={() => setSelectedPlanId(null)}
        />
      )}
    </div>
  )
}
```

**Create Plan Dialog** (`components/migration/CreatePlanDialog.tsx`)
```tsx
export function CreatePlanDialog({ isOpen, onClose, onCreatePlan }: CreatePlanDialogProps) {
  const [formData, setFormData] = useState<CreatePlanFormData>({
    name: '',
    description: '',
    sourceConfig: {
      disks: [],
      paths: [],
      includePatterns: ['*'],
      excludePatterns: [],
      minFileSize: 0,
      maxFileSize: 0,
      fileTypes: []
    },
    destConfig: {
      targetDisk: '',
      basePath: '',
      directoryStructure: DirectoryStructure.FLAT,
      namingRules: [],
      spaceReservation: 1 * GB
    },
    strategy: {
      duplicateHandling: DuplicateStrategy.SKIP,
      conflictResolution: ConflictStrategy.RENAME,
      organizationRules: [],
      batchSize: 1000,
      parallelTasks: 3,
      largeFileThreshold: 100 * MB,
      backupStrategy: BackupStrategy.NONE
    }
  })
  
  const handleSubmit = async () => {
    try {
      await onCreatePlan(formData)
      onClose()
    } catch (error) {
      // Handle error
    }
  }
  
  return (
    <Dialog open={isOpen} onOpenChange={onClose}>
      <DialogContent className="create-plan-dialog">
        <DialogHeader>
          <DialogTitle>Create Migration Plan</DialogTitle>
        </DialogHeader>
        
        <Tabs defaultValue="basic">
          <TabsList>
            <TabsTrigger value="basic">Basic Info</TabsTrigger>
            <TabsTrigger value="source">Source</TabsTrigger>
            <TabsTrigger value="destination">Destination</TabsTrigger>
            <TabsTrigger value="strategy">Strategy</TabsTrigger>
          </TabsList>
          
          <TabsContent value="basic">
            <BasicInfoForm data={formData} onChange={setFormData} />
          </TabsContent>
          <TabsContent value="source">
            <SourceConfigForm data={formData.sourceConfig} onChange={handleSourceChange} />
          </TabsContent>
          <TabsContent value="destination">
            <DestConfigForm data={formData.destConfig} onChange={handleDestChange} />
          </TabsContent>
          <TabsContent value="strategy">
            <StrategyConfigForm data={formData.strategy} onChange={handleStrategyChange} />
          </TabsContent>
        </Tabs>
        
        <DialogFooter>
          <Button variant="outline" onClick={onClose}>Cancel</Button>
          <Button onClick={handleSubmit}>Create Plan</Button>
        </DialogFooter>
      </DialogContent>
    </Dialog>
  )
}
```

**Plan Analysis Display** (`components/migration/PlanAnalysisDisplay.tsx`)
```tsx
export function PlanAnalysisDisplay({ analysis }: { analysis: PlanAnalysis }) {
  return (
    <div className="plan-analysis">
      <div className="analysis-overview">
        <StatCard 
          title="Total Files"
          value={analysis.sourceAnalysis.totalFiles.toLocaleString()}
          icon={FileIcon}
        />
        <StatCard 
          title="Total Size"
          value={formatBytes(analysis.sourceAnalysis.totalSize)}
          icon={HardDriveIcon}
        />
        <StatCard 
          title="Duplicates"
          value={analysis.duplicateAnalysis.duplicateFiles.toLocaleString()}
          icon={CopyIcon}
        />
        <StatCard 
          title="Space Wasted"
          value={formatBytes(analysis.duplicateAnalysis.spaceWastedByDuplicates)}
          icon={TrashIcon}
        />
      </div>
      
      <div className="analysis-details">
        <Tabs defaultValue="source">
          <TabsList>
            <TabsTrigger value="source">Source Analysis</TabsTrigger>
            <TabsTrigger value="duplicates">Duplicates</TabsTrigger>
            <TabsTrigger value="space">Space Planning</TabsTrigger>
            <TabsTrigger value="risks">Risk Assessment</TabsTrigger>
          </TabsList>
          
          <TabsContent value="source">
            <SourceAnalysisTab analysis={analysis.sourceAnalysis} />
          </TabsContent>
          <TabsContent value="duplicates">
            <DuplicateAnalysisTab analysis={analysis.duplicateAnalysis} />
          </TabsContent>
          <TabsContent value="space">
            <SpaceAnalysisTab analysis={analysis.spaceAnalysis} />
          </TabsContent>
          <TabsContent value="risks">
            <RiskAnalysisTab risks={analysis.riskAnalysis} />
          </TabsContent>
        </Tabs>
      </div>
      
      <div className="execution-estimates">
        <div className="estimate-card">
          <h3>Estimated Duration</h3>
          <p>{formatDuration(analysis.estimatedDuration)}</p>
        </div>
        <div className="estimate-card">
          <h3>Resource Requirements</h3>
          <ul>
            <li>CPU: {analysis.resourceRequirements.cpu}%</li>
            <li>Memory: {formatBytes(analysis.resourceRequirements.memory)}</li>
            <li>Disk I/O: {formatBytes(analysis.resourceRequirements.diskIO)}/s</li>
          </ul>
        </div>
      </div>
    </div>
  )
}
```

## Database Schema

**Migration Plans Table** (`migrations/008_migration_plans.sql`)
```sql
CREATE TABLE migration_plans (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    status TEXT NOT NULL CHECK (status IN ('draft', 'analyzing', 'ready', 'executing', 'complete', 'failed')),
    source_config TEXT NOT NULL, -- JSON
    dest_config TEXT NOT NULL,   -- JSON
    strategy TEXT NOT NULL,      -- JSON
    analysis TEXT,               -- JSON, nullable
    created_on INTEGER NOT NULL,
    updated_on INTEGER NOT NULL,
    last_executed_on INTEGER,
    version INTEGER NOT NULL DEFAULT 1
);

CREATE INDEX idx_migration_plans_status ON migration_plans(status);
CREATE INDEX idx_migration_plans_created_on ON migration_plans(created_on);
CREATE INDEX idx_migration_plans_name ON migration_plans(name);

-- Migration plan execution history
CREATE TABLE migration_executions (
    id TEXT PRIMARY KEY,
    plan_id TEXT NOT NULL REFERENCES migration_plans(id) ON DELETE CASCADE,
    started_on INTEGER NOT NULL,
    completed_on INTEGER,
    status TEXT NOT NULL CHECK (status IN ('running', 'complete', 'failed', 'cancelled')),
    tasks_created INTEGER NOT NULL DEFAULT 0,
    tasks_completed INTEGER NOT NULL DEFAULT 0,
    tasks_failed INTEGER NOT NULL DEFAULT 0,
    error_message TEXT,
    execution_log TEXT -- JSON array of log entries
);

CREATE INDEX idx_migration_executions_plan_id ON migration_executions(plan_id);
CREATE INDEX idx_migration_executions_started_on ON migration_executions(started_on);
```

## Validation & Testing

### Unit Tests
- [ ] Migration plan model validation
- [ ] Source data analysis algorithms
- [ ] Duplicate detection accuracy
- [ ] Space calculation correctness
- [ ] Risk assessment logic

### Integration Tests
- [ ] Plan creation and persistence
- [ ] Analysis workflow end-to-end
- [ ] Task generation from plans
- [ ] API endpoint functionality
- [ ] Database operations

### UI Tests
- [ ] Plan creation wizard flow
- [ ] Analysis result display
- [ ] Plan execution confirmation
- [ ] Error handling and feedback
- [ ] Responsive design validation

## Dependencies

**Required Stories:**
- Epic 2 Complete: Task Engine, MD5, MediaInfo, UI, Opportunistic Logic
- Story 1.2: Physical Disk Discovery & Scanning
- Story 1.3: File System Scanning & Cataloging
- Story 1.4: SQLite Database Schema & Operations

**Technical Dependencies:**
- Task engine infrastructure for execution
- MD5 checksums for duplicate detection
- File system scanning capabilities
- Database operations for plan persistence

## Definition of Done

- [ ] Migration plan creation wizard with comprehensive configuration options
- [ ] Source data analysis with file type, size, and duplicate detection
- [ ] Destination planning with space validation and conflict resolution
- [ ] Migration strategy definition with organization rules and handling policies
- [ ] Impact analysis with time/resource estimates and risk assessment
- [ ] Task generation from migration plans for execution via task engine
- [ ] Plan persistence with versioning and modification capabilities
- [ ] Comprehensive UI for plan management and analysis review
- [ ] API endpoints for all plan operations
- [ ] Database schema for plan storage and execution history
- [ ] Full integration with existing task engine infrastructure

## Success Metrics

- **Planning Accuracy:** 95%+ accurate estimates for duration and space requirements
- **Analysis Performance:** Complete analysis of 100K files in under 5 minutes
- **User Experience:** Intuitive wizard flow with clear progress indicators
- **Plan Reliability:** Generated plans execute successfully without manual intervention
- **Resource Efficiency:** Plans optimize for minimal resource usage and maximum throughput

## Next Stories

This story enables:
- **Story 3.2:** Advanced Organization Rules (complex file organization and tagging)
- **Story 3.3:** Migration Execution Engine (executing migration plans via task system)
- **Story 3.4:** Migration Monitoring & Control (real-time progress and intervention)
- **Story 3.5:** Post-Migration Validation (verification and rollback capabilities)

## PRD Requirements Fulfilled

- **Core Value Proposition:** "Intelligent, user-friendly data migration and organization system"
- **FR1:** Disk discovery and file cataloging foundation for migration planning
- **FR2:** Comprehensive file analysis and duplicate detection
- **FR3:** User-defined organization rules and migration strategies
- **FR7:** Task-based execution system integration
- **FR10:** Detailed progress tracking and resource monitoring preparation
- **Migration Planning:** Complete foundation for data migration with analysis and strategy definition


## File List

*To be populated during implementation*

## Dev Agent Record

### Implementation Notes
*To be populated during development*

### Completion Notes
*To be populated upon completion*

### Debug Log References
*To be populated if debugging required*

## QA Results

*To be populated during QA review*
