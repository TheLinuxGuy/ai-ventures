# Story 2.2: MD5 Checksum Background Processing

## Story: MD5 Checksum Calculation Service

## Story
As a user,
I want MediaMogul to calculate and store MD5 checksums for my files as a background task,
So that I can detect duplicate files, verify file integrity, and track when files have been modified or replaced.

## Story Context

**Epic:** 2 - Asynchronous Task Engine & Data Enrichment  
**Dependencies:** Story 2.1 (Task Engine Foundation), Story 1.3 (File System Scanning)  
**Story Type:** Data Enrichment - Background Processing  

This story implements the MD5 checksum calculation capability as a background task using the task engine foundation. It fulfills FR5 from the PRD: "The system shall calculate and store MD5 checksums for files" with intelligent processing that avoids redundant work.

## Acceptance Criteria

### MD5 Task Creation & Scheduling
- [ ] Users can trigger MD5 calculation for individual files via file browser context menu
- [ ] Users can trigger bulk MD5 calculation for entire folders/disks via dashboard
- [ ] System creates `calculate_md5` tasks with appropriate execution priority
- [ ] Tasks include file selection criteria in payload (individual files, folder paths, or disk-wide)
- [ ] Smart scheduling avoids creating duplicate tasks for same files

### MD5 Calculation Logic
- [ ] **Skip existing checksums:** Only calculate MD5 if `files.md5` field is NULL
- [ ] **Skip modified files:** Only calculate MD5 if file has NOT been modified since last checksum
- [ ] **File validation:** Verify file exists and is readable before calculation
- [ ] **Progress tracking:** Update `files_processed` and `bytes_processed` during execution
- [ ] **Atomic updates:** MD5 value and timestamp updated together in single transaction

### Performance Optimization
- [ ] **Streaming calculation:** Process large files without loading entire file into memory
- [ ] **Disk power awareness:** Respect opportunistic execution when disk is sleeping
- [ ] **Batch processing:** Process multiple files in single task efficiently
- [ ] **Resume capability:** Handle task cancellation and resumption gracefully
- [ ] **Resource limiting:** Configurable I/O throttling to prevent system impact

### File Model Integration
- [ ] Store MD5 checksum in `files.md5` field (32-character hexadecimal string)
- [ ] Update `files.last_seen_on` timestamp when MD5 calculated
- [ ] Create file history record with action `md5_calculated` 
- [ ] Handle file-not-found scenarios (mark as deleted, don't fail task)
- [ ] Validate MD5 format before database storage

### User Interface Integration
- [ ] File browser displays MD5 status (calculated/pending/error) with visual indicators
- [ ] MD5 values shown in file details panel with copy-to-clipboard functionality
- [ ] Progress indicator shows MD5 calculation progress for running tasks
- [ ] Bulk actions UI allows starting MD5 calculation on selected files/folders
- [ ] Task queue UI shows MD5 tasks with file count and progress

### Duplicate Detection Foundation
- [ ] After MD5 calculation, identify files with identical checksums
- [ ] Update `files.duplicate_of_uid` field to reference original file when duplicates found
- [ ] Create file history records for duplicate relationships discovered
- [ ] Provide API endpoint to query duplicate files by MD5
- [ ] Handle edge case where original file is deleted (promote duplicate to original)

## Technical Implementation

### Go Backend Components

**MD5 Task Executor** (`internal/service/taskengine/executors/md5.go`)
```go
type MD5TaskExecutor struct {
    fileRepo     repository.FileRepository
    historyRepo  repository.FileHistoryRepository
    logger       zerolog.Logger
    config       MD5Config
}

type MD5TaskPayload struct {
    FileUIDs    []string `json:"file_uids,omitempty"`    // Specific files
    FolderPaths []string `json:"folder_paths,omitempty"` // Entire folders
    DiskGUID    string   `json:"disk_guid,omitempty"`    // Entire disk
    ForceRecalc bool     `json:"force_recalc"`           // Override existing MD5
}

func (e *MD5TaskExecutor) Execute(ctx context.Context, task *Task) error
func (e *MD5TaskExecutor) calculateFileMD5(filepath string) (string, error)
func (e *MD5TaskExecutor) updateFileWithMD5(fileUID, md5Hash string) error
func (e *MD5TaskExecutor) detectDuplicates(md5Hash string) error
```

**MD5 Service** (`internal/service/md5/service.go`)
```go
type Service interface {
    CreateMD5Task(payload MD5TaskPayload, priority ExecutionPriority) (*Task, error)
    GetMD5Statistics(diskGUID string) (*MD5Stats, error)
    FindDuplicateFiles(md5Hash string) ([]*File, error)
    GetMD5Progress() ([]*TaskProgress, error)
}

type MD5Stats struct {
    TotalFiles      int     `json:"total_files"`
    FilesWithMD5    int     `json:"files_with_md5"`
    MD5Coverage     float64 `json:"md5_coverage"`
    DuplicateFiles  int     `json:"duplicate_files"`
    DuplicateBytes  int64   `json:"duplicate_bytes"`
}
```

### API Endpoints
- `POST /api/v1/md5/calculate` - Create MD5 calculation task
- `GET /api/v1/md5/stats` - Get MD5 coverage statistics
- `GET /api/v1/md5/stats/{disk_guid}` - Get disk-specific MD5 stats
- `GET /api/v1/md5/duplicates` - List files with duplicate MD5 checksums
- `GET /api/v1/md5/duplicates/{md5_hash}` - Get all files with specific MD5
- `DELETE /api/v1/md5/{file_uid}` - Clear MD5 checksum for file

### Frontend Components

**MD5 Actions Component** (`components/md5/MD5Actions.tsx`)
- Context menu items for individual files ("Calculate MD5")
- Bulk action buttons for folders/disks ("Calculate MD5 for All")
- Progress indicators during calculation
- MD5 display with copy functionality

**MD5 Statistics Dashboard** (`components/dashboard/MD5Stats.tsx`)
- Coverage percentage per disk
- Duplicate files summary
- Recent MD5 calculation activity
- Quick actions to start bulk MD5 tasks

**Duplicate Files Viewer** (`components/files/DuplicateViewer.tsx`)
- List duplicate files grouped by MD5
- File comparison interface
- Actions to resolve duplicates (delete, ignore)

### Configuration Options
```env
# MD5 Processing Configuration
MD5_BUFFER_SIZE=1048576           # 1MB buffer for streaming reads
MD5_CONCURRENT_FILES=3            # Max files processed simultaneously
MD5_IO_THROTTLE_MS=10            # Milliseconds between I/O operations
MD5_MAX_FILE_SIZE_GB=50          # Skip files larger than this
MD5_BATCH_SIZE=100               # Files processed per task batch
MD5_DUPLICATE_CHECK_ENABLED=true # Enable automatic duplicate detection
```

## Validation & Testing

### Unit Tests
- [ ] MD5 calculation accuracy for various file sizes
- [ ] Duplicate detection logic and edge cases
- [ ] Task payload parsing and validation
- [ ] Error handling for inaccessible files
- [ ] Database transaction integrity

### Integration Tests
- [ ] End-to-end MD5 task execution
- [ ] File browser MD5 display integration
- [ ] Bulk operation performance
- [ ] Task cancellation and recovery
- [ ] Duplicate file relationship handling

### Performance Tests
- [ ] Large file processing (multi-GB files)
- [ ] Bulk processing of many small files
- [ ] Memory usage during streaming calculation
- [ ] I/O impact on system performance
- [ ] Database performance with many duplicates

## Dependencies

**Required Stories:**
- Story 2.1: Task Engine Foundation (task creation, execution, progress tracking)
- Story 1.3: File System Scanning (file discovery and metadata)

**Database Dependencies:**
- `files.md5` field (already in V4 schema)
- `files.last_seen_on` field (already in V4 schema)
- `files.duplicate_of_uid` field (already in V4 schema)
- `file_history` table for audit trail

## Definition of Done

- [ ] MD5 calculation tasks execute successfully for individual files and bulk operations
- [ ] System intelligently skips files that already have valid MD5 checksums
- [ ] Large files process using streaming algorithm without excessive memory usage
- [ ] Duplicate files are automatically detected and relationships stored
- [ ] File browser displays MD5 status and values appropriately
- [ ] Bulk actions UI allows starting MD5 calculation on folders/disks
- [ ] Progress tracking updates accurately during task execution
- [ ] File history maintains audit trail of MD5 calculations
- [ ] Error handling gracefully manages inaccessible or deleted files
- [ ] Performance impact is minimal during background processing
- [ ] All API endpoints implemented and tested
- [ ] Integration tests cover duplicate detection scenarios

## Success Metrics

- **Accuracy:** 100% MD5 calculation accuracy verified against known checksums
- **Performance:** Process 1000+ small files per minute, large files at disk I/O speed
- **Reliability:** <0.1% task failure rate due to application errors
- **Resource Usage:** <100MB memory overhead during processing
- **Duplicate Detection:** 100% accuracy in identifying duplicate file relationships
- **User Experience:** Progress updates within 2 seconds, responsive UI during processing

## Next Stories

This story enables:
- **Story 2.3:** MediaInfo Data Background Processing (similar pattern for media metadata)
- **Story 3.x:** File Migration Planning (use MD5 for integrity verification during moves)
- **Story 4.x:** Duplicate File Management (advanced duplicate resolution tools)

## PRD Requirements Fulfilled

- **FR5:** "The system shall calculate and store MD5 checksums for files. This operation should only be triggered if the file's checksum does not already exist in the database, or if the file has been modified."
- **Smart Processing:** Avoids redundant calculations as specified
- **Background Processing:** Implements as asynchronous task to avoid UI blocking
- **File Integrity:** Provides foundation for detecting file modifications and corruptions
