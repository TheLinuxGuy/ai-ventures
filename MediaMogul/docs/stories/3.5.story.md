# Story 3.5: Post-Migration Validation

## Story

As a user,
I want comprehensive post-migration validation and reporting capabilities,
So that I can verify the success of my migrations with detailed reports, audit trails, and corrective actions for any discrepancies found.

## Story Context

**Epic:** 3 - Migration Planning and Execution  
**Dependencies:** Story 3.1-3.4 (Complete Migration System), Epic 2 Complete  
**Story Type:** Validation & Reporting Feature - Migration Completion  

This story provides the final layer of Epic 3's migration system by implementing comprehensive post-migration validation, detailed reporting, audit trails, and corrective actions. It ensures users have complete confidence in their migration results and provides tools for continuous monitoring and maintenance.

## Acceptance Criteria

### Comprehensive Validation Framework
- [ ] **Integrity validation:** Deep verification of file checksums, sizes, and attributes
- [ ] **Structure validation:** Verify destination directory structure matches migration plan
- [ ] **Completeness validation:** Ensure all planned files were successfully migrated
- [ ] **Metadata validation:** Verify timestamps, permissions, and extended attributes preservation
- [ ] **Duplicate validation:** Confirm duplicate handling worked according to strategy
- [ ] **Organization validation:** Verify files were organized according to rules and tags

### Advanced Reporting System
- [ ] **Migration summary reports:** Comprehensive overview of migration results
- [ ] **Detailed file reports:** Per-file status with before/after comparisons
- [ ] **Performance reports:** Transfer speeds, timing analysis, and bottleneck identification
- [ ] **Error analysis reports:** Categorized errors with resolution recommendations
- [ ] **Space utilization reports:** Disk usage before/after with efficiency metrics
- [ ] **Audit trail reports:** Complete chronological log of all operations

### Data Quality Assessment
- [ ] **Content verification:** Sample-based deep content validation using file signatures
- [ ] **Accessibility testing:** Verify migrated files can be opened and accessed
- [ ] **Corruption detection:** Identify potential file corruption through multiple methods
- [ ] **Orphan detection:** Find files that weren't properly organized or linked
- [ ] **Inconsistency identification:** Detect discrepancies in file organization
- [ ] **Quality scoring:** Overall migration quality metrics and recommendations

### Corrective Actions & Remediation
- [ ] **Automatic remediation:** Fix common issues automatically where safe
- [ ] **Manual remediation tools:** Guided workflows for complex issues
- [ ] **Re-migration planning:** Generate plans to fix identified problems
- [ ] **Rollback capabilities:** Safe rollback of problematic migrations
- [ ] **Incremental fixes:** Apply corrections without full re-migration
- [ ] **Verification re-runs:** Re-validate after corrections are applied

### Long-term Monitoring & Maintenance
- [ ] **Periodic validation:** Scheduled re-validation of migrated data
- [ ] **Drift detection:** Identify changes or degradation over time
- [ ] **Health monitoring:** Ongoing assessment of migrated data integrity
- [ ] **Maintenance recommendations:** Proactive suggestions for data management
- [ ] **Trend analysis:** Historical analysis of migration patterns and quality
- [ ] **Compliance reporting:** Generate reports for regulatory or audit requirements

### Interactive Validation Tools
- [ ] **Visual diff tools:** Side-by-side comparison of source and destination
- [ ] **Sampling tools:** Interactive tools for spot-checking migration results
- [ ] **Search and filter:** Advanced filtering of validation results and reports
- [ ] **Export capabilities:** Export reports in multiple formats (PDF, CSV, JSON)
- [ ] **Collaborative features:** Share reports and findings with team members
- [ ] **Custom validation rules:** User-defined validation criteria and checks

## Technical Implementation

### Backend Components

**Post-Migration Validator** (`internal/services/post_migration_validator.go`)
```go
type PostMigrationValidator struct {
    db                  *database.DB
    fileService         *FileService
    checksumService     *ChecksumService
    migrationExecutor   *MigrationExecutor
    organizationEngine  *OrganizationEngine
    reportService       *ReportService
    logger              *slog.Logger
    validationCache     sync.Map // Cache for expensive validations
}

type ValidationSession struct {
    ID                  string                    `json:"id"`
    ExecutionID         string                    `json:"execution_id"`
    PlanID              string                    `json:"plan_id"`
    Status              ValidationStatus          `json:"status"`
    StartedAt           time.Time                 `json:"started_at"`
    CompletedAt         *time.Time                `json:"completed_at,omitempty"`
    ValidationRules     []ValidationRule          `json:"validation_rules"`
    Results             ValidationResults         `json:"results"`
    Issues              []ValidationIssue         `json:"issues"`
    Recommendations     []Recommendation          `json:"recommendations"`
    CorrectiveActions   []CorrectiveAction        `json:"corrective_actions"`
    QualityScore        float64                   `json:"quality_score"`
}

type ValidationStatus string
const (
    ValidationStatusPending     ValidationStatus = "pending"
    ValidationStatusRunning     ValidationStatus = "running"
    ValidationStatusCompleted   ValidationStatus = "completed"
    ValidationStatusFailed      ValidationStatus = "failed"
    ValidationStatusPartial     ValidationStatus = "partial"
)

type ValidationRule struct {
    ID                  string              `json:"id"`
    Name                string              `json:"name"`
    Description         string              `json:"description"`
    Type                ValidationRuleType  `json:"type"`
    Parameters          map[string]interface{} `json:"parameters"`
    Severity            ValidationSeverity  `json:"severity"`
    Enabled             bool                `json:"enabled"`
    CustomValidator     func(context.Context, interface{}) (*ValidationResult, error) `json:"-"`
}

type ValidationRuleType string
const (
    RuleTypeChecksum        ValidationRuleType = "checksum"
    RuleTypeSize           ValidationRuleType = "size"
    RuleTypeMetadata       ValidationRuleType = "metadata"
    RuleTypeStructure      ValidationRuleType = "structure"
    RuleTypeOrganization   ValidationRuleType = "organization"
    RuleTypeContent        ValidationRuleType = "content"
    RuleTypeAccessibility  ValidationRuleType = "accessibility"
    RuleTypeCustom         ValidationRuleType = "custom"
)

type ValidationResults struct {
    TotalFiles          int64                      `json:"total_files"`
    ValidatedFiles      int64                      `json:"validated_files"`
    PassedValidation    int64                      `json:"passed_validation"`
    FailedValidation    int64                      `json:"failed_validation"`
    SkippedValidation   int64                      `json:"skipped_validation"`
    TotalBytes          int64                      `json:"total_bytes"`
    ValidatedBytes      int64                      `json:"validated_bytes"`
    ValidationTime      time.Duration              `json:"validation_time"`
    RuleResults         map[string]*RuleResult     `json:"rule_results"`
    PerformanceMetrics  ValidationPerformanceMetrics `json:"performance_metrics"`
}

type ValidationIssue struct {
    ID                  string                  `json:"id"`
    RuleID              string                  `json:"rule_id"`
    Severity            ValidationSeverity      `json:"severity"`
    Type                IssueType               `json:"type"`
    FilePath            string                  `json:"file_path,omitempty"`
    Description         string                  `json:"description"`
    ExpectedValue       interface{}             `json:"expected_value,omitempty"`
    ActualValue         interface{}             `json:"actual_value,omitempty"`
    Recommendation      string                  `json:"recommendation"`
    CanAutoFix          bool                    `json:"can_auto_fix"`
    EstimatedFixTime    time.Duration           `json:"estimated_fix_time"`
    RelatedFiles        []string                `json:"related_files,omitempty"`
    Metadata            map[string]interface{}  `json:"metadata,omitempty"`
}

func NewPostMigrationValidator(deps ServiceDependencies) *PostMigrationValidator {
    return &PostMigrationValidator{
        db:                 deps.DB,
        fileService:       deps.FileService,
        checksumService:   deps.ChecksumService,
        migrationExecutor: deps.MigrationExecutor,
        organizationEngine: deps.OrganizationEngine,
        reportService:     deps.ReportService,
        logger:            deps.Logger.With("service", "post_migration_validator"),
    }
}

// StartValidation begins comprehensive validation of a completed migration
func (v *PostMigrationValidator) StartValidation(ctx context.Context, executionID string, rules []ValidationRule) (*ValidationSession, error) {
    // Get execution context and migration plan
    execCtx, err := v.migrationExecutor.GetExecutionContext(executionID)
    if err != nil {
        return nil, fmt.Errorf("failed to get execution context: %w", err)
    }
    
    if execCtx.Status != ExecutionStatusCompleted {
        return nil, fmt.Errorf("can only validate completed migrations, current status: %s", execCtx.Status)
    }
    
    plan, err := v.migrationExecutor.plannerService.GetPlan(ctx, execCtx.PlanID)
    if err != nil {
        return nil, fmt.Errorf("failed to get migration plan: %w", err)
    }
    
    // Create validation session
    session := &ValidationSession{
        ID:               generateValidationID(),
        ExecutionID:      executionID,
        PlanID:           execCtx.PlanID,
        Status:           ValidationStatusPending,
        StartedAt:        time.Now(),
        ValidationRules:  rules,
        Results:          ValidationResults{RuleResults: make(map[string]*RuleResult)},
        Issues:           []ValidationIssue{},
        Recommendations:  []Recommendation{},
        CorrectiveActions: []CorrectiveAction{},
    }
    
    // Store session in database
    if err := v.storeValidationSession(ctx, session); err != nil {
        return nil, fmt.Errorf("failed to store validation session: %w", err)
    }
    
    // Start validation in background
    go v.performValidation(ctx, session, plan, execCtx)
    
    v.logger.Info("Post-migration validation started", 
        "session_id", session.ID, 
        "execution_id", executionID, 
        "rules", len(rules))
    
    return session, nil
}

// performValidation executes the validation process
func (v *PostMigrationValidator) performValidation(ctx context.Context, session *ValidationSession, plan *MigrationPlan, execCtx *ExecutionContext) {
    session.Status = ValidationStatusRunning
    v.updateValidationSession(ctx, session)
    
    defer func() {
        if r := recover(); r != nil {
            v.logger.Error("Validation panic", "session_id", session.ID, "panic", r)
            session.Status = ValidationStatusFailed
            session.CompletedAt = timePtr(time.Now())
            v.updateValidationSession(ctx, session)
        }
    }()
    
    startTime := time.Now()
    
    // Get list of files that should have been migrated
    migratedFiles, err := v.getMigratedFilesList(ctx, plan, execCtx)
    if err != nil {
        v.logger.Error("Failed to get migrated files list", "session_id", session.ID, "error", err)
        session.Status = ValidationStatusFailed
        session.CompletedAt = timePtr(time.Now())
        v.updateValidationSession(ctx, session)
        return
    }
    
    session.Results.TotalFiles = int64(len(migratedFiles))
    
    // Execute validation rules
    var allIssues []ValidationIssue
    var totalValidated, totalPassed, totalFailed, totalSkipped int64
    
    for _, rule := range session.ValidationRules {
        if !rule.Enabled {
            continue
        }
        
        v.logger.Info("Executing validation rule", "session_id", session.ID, "rule", rule.Name)
        
        ruleResult, issues := v.executeValidationRule(ctx, rule, migratedFiles, plan, execCtx)
        session.Results.RuleResults[rule.ID] = ruleResult
        allIssues = append(allIssues, issues...)
        
        totalValidated += ruleResult.FilesValidated
        totalPassed += ruleResult.FilesPassed
        totalFailed += ruleResult.FilesFailed
        totalSkipped += ruleResult.FilesSkipped
        
        // Update progress
        session.Results.ValidatedFiles = totalValidated
        session.Results.PassedValidation = totalPassed
        session.Results.FailedValidation = totalFailed
        session.Results.SkippedValidation = totalSkipped
        v.updateValidationSession(ctx, session)
    }
    
    // Finalize results
    session.Results.ValidationTime = time.Since(startTime)
    session.Issues = allIssues
    
    // Generate recommendations and corrective actions
    session.Recommendations = v.generateRecommendations(ctx, session, allIssues)
    session.CorrectiveActions = v.generateCorrectiveActions(ctx, session, allIssues)
    
    // Calculate quality score
    session.QualityScore = v.calculateQualityScore(session)
    
    // Determine final status
    if totalFailed == 0 {
        session.Status = ValidationStatusCompleted
    } else if totalPassed > 0 {
        session.Status = ValidationStatusPartial
    } else {
        session.Status = ValidationStatusFailed
    }
    
    session.CompletedAt = timePtr(time.Now())
    v.updateValidationSession(ctx, session)
    
    // Generate comprehensive report
    v.generateValidationReport(ctx, session)
    
    v.logger.Info("Post-migration validation completed", 
        "session_id", session.ID, 
        "status", session.Status,
        "quality_score", session.QualityScore,
        "issues", len(allIssues))
}

// executeValidationRule runs a specific validation rule
func (v *PostMigrationValidator) executeValidationRule(ctx context.Context, rule ValidationRule, files []MigratedFile, plan *MigrationPlan, execCtx *ExecutionContext) (*RuleResult, []ValidationIssue) {
    result := &RuleResult{
        RuleID:         rule.ID,
        RuleName:       rule.Name,
        StartedAt:      time.Now(),
        FilesValidated: 0,
        FilesPassed:    0,
        FilesFailed:    0,
        FilesSkipped:   0,
    }
    
    var issues []ValidationIssue
    
    switch rule.Type {
    case RuleTypeChecksum:
        result, issues = v.validateChecksums(ctx, rule, files)
    case RuleTypeSize:
        result, issues = v.validateFileSizes(ctx, rule, files)
    case RuleTypeMetadata:
        result, issues = v.validateMetadata(ctx, rule, files)
    case RuleTypeStructure:
        result, issues = v.validateStructure(ctx, rule, plan)
    case RuleTypeOrganization:
        result, issues = v.validateOrganization(ctx, rule, files, plan)
    case RuleTypeContent:
        result, issues = v.validateContent(ctx, rule, files)
    case RuleTypeAccessibility:
        result, issues = v.validateAccessibility(ctx, rule, files)
    case RuleTypeCustom:
        if rule.CustomValidator != nil {
            result, issues = v.executeCustomValidation(ctx, rule, files)
        }
    }
    
    result.CompletedAt = timePtr(time.Now())
    result.ValidationTime = time.Since(result.StartedAt)
    
    return result, issues
}

// validateChecksums verifies file integrity using checksums
func (v *PostMigrationValidator) validateChecksums(ctx context.Context, rule ValidationRule, files []MigratedFile) (*RuleResult, []ValidationIssue) {
    result := &RuleResult{RuleID: rule.ID, RuleName: rule.Name, StartedAt: time.Now()}
    var issues []ValidationIssue
    
    // Get checksum algorithm from rule parameters
    algorithm, _ := rule.Parameters["algorithm"].(string)
    if algorithm == "" {
        algorithm = "md5" // Default
    }
    
    sampleSize, _ := rule.Parameters["sample_size"].(float64)
    if sampleSize == 0 {
        sampleSize = 1.0 // Validate all files by default
    }
    
    // Select files to validate based on sample size
    filesToValidate := v.selectFileSample(files, sampleSize)
    result.FilesValidated = int64(len(filesToValidate))
    
    for _, file := range filesToValidate {
        // Check if both source and destination exist
        srcExists := v.fileExists(file.SourcePath)
        dstExists := v.fileExists(file.DestinationPath)
        
        if !srcExists || !dstExists {
            issues = append(issues, ValidationIssue{
                ID:             generateIssueID(),
                RuleID:         rule.ID,
                Severity:       ValidationSeverityError,
                Type:           IssueTypeMissingFile,
                FilePath:       file.DestinationPath,
                Description:    fmt.Sprintf("Source or destination file missing: src_exists=%v, dst_exists=%v", srcExists, dstExists),
                CanAutoFix:     false,
                Recommendation: "Check migration logs and re-run migration for this file",
            })
            result.FilesFailed++
            continue
        }
        
        // Calculate checksums
        srcChecksum, err := v.checksumService.CalculateChecksum(file.SourcePath, algorithm)
        if err != nil {
            issues = append(issues, ValidationIssue{
                ID:             generateIssueID(),
                RuleID:         rule.ID,
                Severity:       ValidationSeverityWarning,
                Type:           IssueTypeChecksumCalculationFailed,
                FilePath:       file.SourcePath,
                Description:    fmt.Sprintf("Failed to calculate source checksum: %v", err),
                CanAutoFix:     false,
                Recommendation: "Verify file accessibility and integrity",
            })
            result.FilesSkipped++
            continue
        }
        
        dstChecksum, err := v.checksumService.CalculateChecksum(file.DestinationPath, algorithm)
        if err != nil {
            issues = append(issues, ValidationIssue{
                ID:             generateIssueID(),
                RuleID:         rule.ID,
                Severity:       ValidationSeverityError,
                Type:           IssueTypeChecksumCalculationFailed,
                FilePath:       file.DestinationPath,
                Description:    fmt.Sprintf("Failed to calculate destination checksum: %v", err),
                CanAutoFix:     false,
                Recommendation: "Re-migrate this file to ensure integrity",
            })
            result.FilesFailed++
            continue
        }
        
        // Compare checksums
        if srcChecksum != dstChecksum {
            issues = append(issues, ValidationIssue{
                ID:              generateIssueID(),
                RuleID:          rule.ID,
                Severity:        ValidationSeverityError,
                Type:            IssueTypeChecksumMismatch,
                FilePath:        file.DestinationPath,
                Description:     "File checksum mismatch indicates corruption or incomplete transfer",
                ExpectedValue:   srcChecksum,
                ActualValue:     dstChecksum,
                CanAutoFix:      true,
                EstimatedFixTime: v.estimateReTransferTime(file),
                Recommendation:  "Re-migrate this file to restore integrity",
                RelatedFiles:    []string{file.SourcePath},
            })
            result.FilesFailed++
        } else {
            result.FilesPassed++
        }
    }
    
    return result, issues
}

// validateStructure verifies destination directory structure
func (v *PostMigrationValidator) validateStructure(ctx context.Context, rule ValidationRule, plan *MigrationPlan) (*RuleResult, []ValidationIssue) {
    result := &RuleResult{RuleID: rule.ID, RuleName: rule.Name, StartedAt: time.Now()}
    var issues []ValidationIssue
    
    // Get expected directory structure from migration plan
    expectedDirs := v.getExpectedDirectories(plan)
    result.FilesValidated = int64(len(expectedDirs))
    
    for _, expectedDir := range expectedDirs {
        if !v.directoryExists(expectedDir) {
            issues = append(issues, ValidationIssue{
                ID:              generateIssueID(),
                RuleID:          rule.ID,
                Severity:        ValidationSeverityError,
                Type:            IssueTypeMissingDirectory,
                FilePath:        expectedDir,
                Description:     "Expected directory was not created during migration",
                CanAutoFix:      true,
                EstimatedFixTime: time.Second,
                Recommendation:  "Create missing directory structure",
            })
            result.FilesFailed++
        } else {
            result.FilesPassed++
        }
    }
    
    // Check for unexpected directories
    actualDirs := v.getActualDirectories(plan.DestConfig.BasePath)
    for _, actualDir := range actualDirs {
        if !v.isExpectedDirectory(actualDir, expectedDirs) {
            issues = append(issues, ValidationIssue{
                ID:             generateIssueID(),
                RuleID:         rule.ID,
                Severity:       ValidationSeverityWarning,
                Type:           IssueTypeUnexpectedDirectory,
                FilePath:       actualDir,
                Description:    "Directory was created that wasn't in the migration plan",
                CanAutoFix:     false,
                Recommendation: "Review migration rules and organization logic",
            })
        }
    }
    
    return result, issues
}

// generateCorrectiveActions creates actionable remediation plans
func (v *PostMigrationValidator) generateCorrectiveActions(ctx context.Context, session *ValidationSession, issues []ValidationIssue) []CorrectiveAction {
    var actions []CorrectiveAction
    
    // Group issues by type for efficient handling
    issueGroups := v.groupIssuesByType(issues)
    
    for issueType, typeIssues := range issueGroups {
        switch issueType {
        case IssueTypeChecksumMismatch:
            actions = append(actions, v.createReTransferAction(typeIssues))
        case IssueTypeMissingFile:
            actions = append(actions, v.createMissingFileAction(typeIssues))
        case IssueTypeMissingDirectory:
            actions = append(actions, v.createDirectoryAction(typeIssues))
        case IssueTypeMetadataMismatch:
            actions = append(actions, v.createMetadataFixAction(typeIssues))
        case IssueTypeOrganizationError:
            actions = append(actions, v.createReorganizationAction(typeIssues))
        }
    }
    
    return actions
}

func (v *PostMigrationValidator) createReTransferAction(issues []ValidationIssue) CorrectiveAction {
    var filePaths []string
    var totalEstimatedTime time.Duration
    
    for _, issue := range issues {
        filePaths = append(filePaths, issue.FilePath)
        totalEstimatedTime += issue.EstimatedFixTime
    }
    
    return CorrectiveAction{
        ID:                generateActionID(),
        Type:              ActionTypeReTransfer,
        Title:             fmt.Sprintf("Re-transfer %d corrupted files", len(issues)),
        Description:       "Re-migrate files that failed checksum validation to restore integrity",
        Priority:          ActionPriorityHigh,
        EstimatedTime:     totalEstimatedTime,
        CanAutoExecute:    true,
        RequiresApproval:  false,
        AffectedFiles:     filePaths,
        Parameters: map[string]interface{}{
            "files":           filePaths,
            "verify_checksum": true,
            "backup_existing": true,
        },
        PreConditions:  []string{"Source files must be accessible", "Sufficient disk space"},
        PostValidation: []string{"Verify checksums match", "Update file records"},
    }
}
```

**Validation Report Service** (`internal/services/validation_report_service.go`)
```go
type ValidationReportService struct {
    db              *database.DB
    validator       *PostMigrationValidator
    templateService *TemplateService
    exportService   *ExportService
    logger          *slog.Logger
}

type ValidationReport struct {
    ID                  string                    `json:"id"`
    SessionID           string                    `json:"session_id"`
    ReportType          ReportType                `json:"report_type"`
    GeneratedAt         time.Time                 `json:"generated_at"`
    ExecutiveSummary    ExecutiveSummary          `json:"executive_summary"`
    DetailedFindings    []DetailedFinding         `json:"detailed_findings"`
    PerformanceAnalysis PerformanceAnalysis       `json:"performance_analysis"`
    RiskAssessment      RiskAssessment            `json:"risk_assessment"`
    Recommendations     []RecommendationDetail    `json:"recommendations"`
    ComplianceStatus    ComplianceStatus          `json:"compliance_status"`
    Appendices          map[string]interface{}    `json:"appendices"`
}

type ExecutiveSummary struct {
    MigrationOverview     string                 `json:"migration_overview"`
    OverallStatus         string                 `json:"overall_status"`
    QualityScore          float64                `json:"quality_score"`
    FilesProcessed        int64                  `json:"files_processed"`
    DataTransferred       int64                  `json:"data_transferred"`
    MigrationTime         time.Duration          `json:"migration_time"`
    ValidationTime        time.Duration          `json:"validation_time"`
    IssuesFound           int                    `json:"issues_found"`
    CriticalIssues        int                    `json:"critical_issues"`
    SuccessRate           float64                `json:"success_rate"`
    KeyFindings           []string               `json:"key_findings"`
    RecommendedActions    []string               `json:"recommended_actions"`
}

func (r *ValidationReportService) GenerateComprehensiveReport(ctx context.Context, sessionID string, reportType ReportType) (*ValidationReport, error) {
    session, err := r.validator.GetValidationSession(ctx, sessionID)
    if err != nil {
        return nil, fmt.Errorf("failed to get validation session: %w", err)
    }
    
    report := &ValidationReport{
        ID:          generateReportID(),
        SessionID:   sessionID,
        ReportType:  reportType,
        GeneratedAt: time.Now(),
    }
    
    // Generate executive summary
    report.ExecutiveSummary = r.generateExecutiveSummary(session)
    
    // Generate detailed findings
    report.DetailedFindings = r.generateDetailedFindings(session)
    
    // Performance analysis
    report.PerformanceAnalysis = r.generatePerformanceAnalysis(session)
    
    // Risk assessment
    report.RiskAssessment = r.generateRiskAssessment(session)
    
    // Enhanced recommendations
    report.Recommendations = r.generateDetailedRecommendations(session)
    
    // Compliance status
    report.ComplianceStatus = r.generateComplianceStatus(session)
    
    // Technical appendices
    report.Appendices = r.generateAppendices(session)
    
    // Store report
    if err := r.storeReport(ctx, report); err != nil {
        r.logger.Error("Failed to store validation report", "report_id", report.ID, "error", err)
    }
    
    return report, nil
}
```

### API Endpoints

**Post-Migration Validation API** (`internal/api/post_migration_validation.go`)
```go
// POST /api/v1/migration-executions/:id/validate
func (h *PostMigrationValidationHandler) StartValidation(c *gin.Context) {
    executionID := c.Param("id")
    
    var req StartValidationRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": "Invalid request body", "details": err.Error()})
        return
    }
    
    // Apply default rules if none specified
    if len(req.ValidationRules) == 0 {
        req.ValidationRules = h.validator.GetDefaultValidationRules()
    }
    
    session, err := h.validator.StartValidation(c.Request.Context(), executionID, req.ValidationRules)
    if err != nil {
        h.logger.Error("Failed to start validation", "execution_id", executionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to start validation", "details": err.Error()})
        return
    }
    
    c.JSON(202, gin.H{
        "message": "Validation started",
        "session_id": session.ID,
        "status": session.Status,
    })
}

// GET /api/v1/validation-sessions/:id
func (h *PostMigrationValidationHandler) GetValidationSession(c *gin.Context) {
    sessionID := c.Param("id")
    
    session, err := h.validator.GetValidationSession(c.Request.Context(), sessionID)
    if err != nil {
        if errors.Is(err, ErrValidationSessionNotFound) {
            c.JSON(404, gin.H{"error": "Validation session not found"})
            return
        }
        h.logger.Error("Failed to get validation session", "session_id", sessionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to get validation session"})
        return
    }
    
    c.JSON(200, session)
}

// GET /api/v1/validation-sessions/:id/report
func (h *PostMigrationValidationHandler) GenerateReport(c *gin.Context) {
    sessionID := c.Param("id")
    reportType := c.Query("type")
    if reportType == "" {
        reportType = "comprehensive"
    }
    
    report, err := h.reportService.GenerateComprehensiveReport(c.Request.Context(), sessionID, ReportType(reportType))
    if err != nil {
        h.logger.Error("Failed to generate validation report", "session_id", sessionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to generate report"})
        return
    }
    
    c.JSON(200, report)
}

// POST /api/v1/validation-sessions/:id/actions/:actionId/execute
func (h *PostMigrationValidationHandler) ExecuteCorrectiveAction(c *gin.Context) {
    sessionID := c.Param("id")
    actionID := c.Param("actionId")
    
    var req ExecuteActionRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": "Invalid request body", "details": err.Error()})
        return
    }
    
    execution, err := h.validator.ExecuteCorrectiveAction(c.Request.Context(), sessionID, actionID, req.Parameters)
    if err != nil {
        h.logger.Error("Failed to execute corrective action", "session_id", sessionID, "action_id", actionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to execute action", "details": err.Error()})
        return
    }
    
    c.JSON(202, gin.H{
        "message": "Corrective action started",
        "execution_id": execution.ID,
        "status": execution.Status,
    })
}

// GET /api/v1/validation-sessions/:id/issues
func (h *PostMigrationValidationHandler) GetValidationIssues(c *gin.Context) {
    sessionID := c.Param("id")
    
    // Parse query parameters
    severity := c.Query("severity")
    issueType := c.Query("type")
    canAutoFix := c.Query("can_auto_fix")
    
    issues, err := h.validator.GetValidationIssues(c.Request.Context(), sessionID, ValidationIssueFilter{
        Severity:    severity,
        Type:        issueType,
        CanAutoFix:  parseBoolParam(canAutoFix),
    })
    if err != nil {
        h.logger.Error("Failed to get validation issues", "session_id", sessionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to get validation issues"})
        return
    }
    
    c.JSON(200, gin.H{"issues": issues})
}
```

### Frontend Components

**Post-Migration Validation Dashboard** (`app/migration/validation/[sessionId]/page.tsx`)
```tsx
'use client'
export default function ValidationDashboardPage({ params }: { params: { sessionId: string } }) {
  const { session, isLoading, retryValidation } = useValidationSession(params.sessionId)
  const [activeTab, setActiveTab] = useState('overview')
  
  if (isLoading) {
    return <ValidationLoadingSkeleton />
  }
  
  if (!session) {
    return <ValidationNotFound />
  }
  
  return (
    <div className="validation-dashboard">
      <ValidationHeader 
        session={session}
        onRetry={retryValidation}
      />
      
      <Tabs value={activeTab} onValueChange={setActiveTab}>
        <TabsList className="validation-tabs">
          <TabsTrigger value="overview">Overview</TabsTrigger>
          <TabsTrigger value="issues">Issues</TabsTrigger>
          <TabsTrigger value="reports">Reports</TabsTrigger>
          <TabsTrigger value="actions">Corrective Actions</TabsTrigger>
          <TabsTrigger value="monitoring">Monitoring</TabsTrigger>
        </TabsList>
        
        <TabsContent value="overview">
          <div className="validation-overview">
            <ValidationSummary session={session} />
            <QualityScoreCard score={session.qualityScore} />
            <ValidationProgress session={session} />
          </div>
        </TabsContent>
        
        <TabsContent value="issues">
          <ValidationIssues session={session} />
        </TabsContent>
        
        <TabsContent value="reports">
          <ValidationReports sessionId={params.sessionId} />
        </TabsContent>
        
        <TabsContent value="actions">
          <CorrectiveActions sessionId={params.sessionId} />
        </TabsContent>
        
        <TabsContent value="monitoring">
          <ValidationMonitoring sessionId={params.sessionId} />
        </TabsContent>
      </Tabs>
    </div>
  )
}
```

**Validation Issues Component** (`components/migration/ValidationIssues.tsx`)
```tsx
export function ValidationIssues({ session }: { session: ValidationSession }) {
  const { issues, isLoading, executeAutoFix } = useValidationIssues(session.id)
  const [filterSeverity, setFilterSeverity] = useState<string>('all')
  const [filterType, setFilterType] = useState<string>('all')
  const [showAutoFixable, setShowAutoFixable] = useState(false)
  
  const filteredIssues = useMemo(() => {
    return issues?.filter(issue => {
      if (filterSeverity !== 'all' && issue.severity !== filterSeverity) return false
      if (filterType !== 'all' && issue.type !== filterType) return false
      if (showAutoFixable && !issue.canAutoFix) return false
      return true
    }) || []
  }, [issues, filterSeverity, filterType, showAutoFixable])
  
  return (
    <div className="validation-issues">
      <div className="issues-header">
        <div className="issues-stats">
          <StatCard 
            title="Total Issues"
            value={issues?.length || 0}
            icon={AlertTriangleIcon}
            variant="warning"
          />
          <StatCard 
            title="Critical Issues"
            value={issues?.filter(i => i.severity === 'error').length || 0}
            icon={XCircleIcon}
            variant="destructive"
          />
          <StatCard 
            title="Auto-fixable"
            value={issues?.filter(i => i.canAutoFix).length || 0}
            icon={WrenchIcon}
            variant="default"
          />
        </div>
        
        <div className="issues-filters">
          <Select value={filterSeverity} onValueChange={setFilterSeverity}>
            <SelectTrigger>
              <SelectValue placeholder="Filter by severity" />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="all">All Severities</SelectItem>
              <SelectItem value="error">Critical</SelectItem>
              <SelectItem value="warning">Warning</SelectItem>
              <SelectItem value="info">Info</SelectItem>
            </SelectContent>
          </Select>
          
          <Select value={filterType} onValueChange={setFilterType}>
            <SelectTrigger>
              <SelectValue placeholder="Filter by type" />
            </SelectTrigger>
            <SelectContent>
              <SelectItem value="all">All Types</SelectItem>
              <SelectItem value="checksum_mismatch">Checksum Issues</SelectItem>
              <SelectItem value="missing_file">Missing Files</SelectItem>
              <SelectItem value="metadata_mismatch">Metadata Issues</SelectItem>
              <SelectItem value="organization_error">Organization Issues</SelectItem>
            </SelectContent>
          </Select>
          
          <div className="filter-toggle">
            <Checkbox 
              checked={showAutoFixable} 
              onCheckedChange={setShowAutoFixable}
            />
            <label>Show only auto-fixable</label>
          </div>
        </div>
      </div>
      
      {isLoading ? (
        <IssuesLoadingSkeleton />
      ) : (
        <div className="issues-list">
          {filteredIssues.map(issue => (
            <ValidationIssueCard 
              key={issue.id}
              issue={issue}
              onAutoFix={() => executeAutoFix(issue.id)}
            />
          ))}
        </div>
      )}
    </div>
  )
}
```

**Quality Score Card** (`components/migration/QualityScoreCard.tsx`)
```tsx
export function QualityScoreCard({ score }: { score: number }) {
  const getScoreColor = (score: number) => {
    if (score >= 90) return 'text-green-600'
    if (score >= 70) return 'text-yellow-600'
    return 'text-red-600'
  }
  
  const getScoreGrade = (score: number) => {
    if (score >= 95) return 'A+'
    if (score >= 90) return 'A'
    if (score >= 85) return 'B+'
    if (score >= 80) return 'B'
    if (score >= 70) return 'C'
    return 'D'
  }
  
  return (
    <Card className="quality-score-card">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <TrophyIcon className="h-5 w-5" />
          Migration Quality Score
        </CardTitle>
      </CardHeader>
      <CardContent>
        <div className="score-display">
          <div className={`score-number ${getScoreColor(score)}`}>
            {score.toFixed(1)}
          </div>
          <div className="score-grade">
            Grade: {getScoreGrade(score)}
          </div>
        </div>
        
        <div className="score-breakdown">
          <div className="score-bar">
            <div 
              className="score-fill" 
              style={{ width: `${score}%` }}
            />
          </div>
          
          <div className="score-metrics">
            <div className="metric">
              <span>File Integrity</span>
              <span>{(score * 0.4).toFixed(1)}%</span>
            </div>
            <div className="metric">
              <span>Organization Quality</span>
              <span>{(score * 0.3).toFixed(1)}%</span>
            </div>
            <div className="metric">
              <span>Completeness</span>
              <span>{(score * 0.2).toFixed(1)}%</span>
            </div>
            <div className="metric">
              <span>Performance</span>
              <span>{(score * 0.1).toFixed(1)}%</span>
            </div>
          </div>
        </div>
      </CardContent>
    </Card>
  )
}
```

## Database Schema

**Post-Migration Validation Tables** (`migrations/011_post_migration_validation.sql`)
```sql
CREATE TABLE validation_sessions (
    id TEXT PRIMARY KEY,
    execution_id TEXT NOT NULL REFERENCES migration_executions(execution_id) ON DELETE CASCADE,
    plan_id TEXT NOT NULL REFERENCES migration_plans(id) ON DELETE CASCADE,
    status TEXT NOT NULL CHECK (status IN ('pending', 'running', 'completed', 'failed', 'partial')),
    started_at INTEGER NOT NULL,
    completed_at INTEGER,
    validation_rules TEXT NOT NULL,     -- JSON array of ValidationRule
    results TEXT NOT NULL,             -- JSON ValidationResults
    issues TEXT NOT NULL,              -- JSON array of ValidationIssue
    recommendations TEXT NOT NULL,      -- JSON array of Recommendation
    corrective_actions TEXT NOT NULL,   -- JSON array of CorrectiveAction
    quality_score REAL NOT NULL DEFAULT 0.0,
    metadata TEXT                      -- JSON additional metadata
);

CREATE INDEX idx_validation_sessions_execution_id ON validation_sessions(execution_id);
CREATE INDEX idx_validation_sessions_plan_id ON validation_sessions(plan_id);
CREATE INDEX idx_validation_sessions_status ON validation_sessions(status);
CREATE INDEX idx_validation_sessions_started_at ON validation_sessions(started_at);
CREATE INDEX idx_validation_sessions_quality_score ON validation_sessions(quality_score);

CREATE TABLE validation_reports (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL REFERENCES validation_sessions(id) ON DELETE CASCADE,
    report_type TEXT NOT NULL,
    generated_at INTEGER NOT NULL,
    executive_summary TEXT NOT NULL,    -- JSON ExecutiveSummary
    detailed_findings TEXT NOT NULL,    -- JSON array of DetailedFinding
    performance_analysis TEXT NOT NULL, -- JSON PerformanceAnalysis
    risk_assessment TEXT NOT NULL,     -- JSON RiskAssessment
    recommendations TEXT NOT NULL,      -- JSON array of RecommendationDetail
    compliance_status TEXT NOT NULL,   -- JSON ComplianceStatus
    appendices TEXT NOT NULL,          -- JSON map of appendices
    export_formats TEXT               -- JSON array of available export formats
);

CREATE INDEX idx_validation_reports_session_id ON validation_reports(session_id);
CREATE INDEX idx_validation_reports_generated_at ON validation_reports(generated_at);

CREATE TABLE corrective_action_executions (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL REFERENCES validation_sessions(id) ON DELETE CASCADE,
    action_id TEXT NOT NULL,
    status TEXT NOT NULL CHECK (status IN ('pending', 'running', 'completed', 'failed', 'cancelled')),
    started_at INTEGER NOT NULL,
    completed_at INTEGER,
    parameters TEXT NOT NULL,          -- JSON action parameters
    results TEXT NOT NULL,             -- JSON execution results
    affected_files TEXT NOT NULL,      -- JSON array of file paths
    errors TEXT NOT NULL              -- JSON array of execution errors
);

CREATE INDEX idx_corrective_action_executions_session_id ON corrective_action_executions(session_id);
CREATE INDEX idx_corrective_action_executions_status ON corrective_action_executions(status);

CREATE TABLE validation_file_samples (
    id TEXT PRIMARY KEY,
    session_id TEXT NOT NULL REFERENCES validation_sessions(id) ON DELETE CASCADE,
    file_path TEXT NOT NULL,
    validation_results TEXT NOT NULL,  -- JSON per-file validation results
    issues TEXT NOT NULL,             -- JSON array of file-specific issues
    sample_metadata TEXT NOT NULL     -- JSON sampling and validation metadata
);

CREATE INDEX idx_validation_file_samples_session_id ON validation_file_samples(session_id);
CREATE INDEX idx_validation_file_samples_file_path ON validation_file_samples(file_path);
```

## Validation & Testing

### Post-Migration Validation Tests
- [ ] Comprehensive validation workflow from start to finish
- [ ] All validation rule types and combinations
- [ ] Issue detection and classification accuracy
- [ ] Corrective action generation and execution
- [ ] Quality score calculation and reliability

### Report Generation Tests
- [ ] Report generation for various validation scenarios
- [ ] Export functionality in multiple formats
- [ ] Executive summary accuracy and completeness
- [ ] Performance analysis and metrics calculation
- [ ] Compliance reporting and audit trail generation

### Integration Tests
- [ ] Integration with migration execution system
- [ ] Database operations and schema validation
- [ ] API endpoints and error handling
- [ ] Frontend components and user interactions
- [ ] Long-term monitoring and periodic validation

## Dependencies

**Required Stories:**
- Story 3.1: Migration Planning Foundation
- Story 3.2: Advanced Organization Rules
- Story 3.3: Migration Execution Engine
- Story 3.4: Migration Monitoring & Control
- Epic 2 Complete: Task Engine, MD5, MediaInfo, UI, Opportunistic Logic

**Technical Dependencies:**
- Completed migration execution for validation
- File system access for verification
- Checksum calculation capabilities
- Report generation and export functionality

## Definition of Done

- [ ] Comprehensive validation framework with multiple validation rules
- [ ] Advanced reporting system with executive summaries and detailed findings
- [ ] Data quality assessment with corruption detection and accessibility testing
- [ ] Corrective actions and remediation workflows with guided fixes
- [ ] Long-term monitoring and maintenance capabilities with drift detection
- [ ] Interactive validation tools with visual diff and sampling capabilities
- [ ] Complete API endpoints for all validation and reporting operations
- [ ] Frontend dashboard with quality scoring and issue management
- [ ] Database schema supporting validation sessions and report storage
- [ ] Integration with existing migration system and task management

## Success Metrics

- **Validation Accuracy:** 99.95%+ accuracy in detecting file integrity issues
- **Issue Resolution:** 95%+ of auto-fixable issues successfully resolved
- **Report Quality:** Comprehensive reports covering all aspects of migration quality
- **User Confidence:** High user satisfaction with validation completeness and clarity
- **Performance:** Validation completion within 10% of migration execution time

## Next Stories

This story completes Epic 3 and enables:
- **Epic 4:** External Services Integration (cloud storage, network drives)
- **Epic 5:** Advanced Analytics and Insights (usage patterns, optimization suggestions)
- **Epic 6:** Enterprise Features (multi-tenant, RBAC, audit logging)

## PRD Requirements Fulfilled

- **Core Value Proposition:** Complete confidence in migration success with comprehensive validation
- **FR11:** Post-migration validation with integrity verification and quality assessment
- **FR12:** Comprehensive reporting with executive summaries and technical details
- **FR13:** Corrective actions and remediation workflows for identified issues
- **FR14:** Long-term monitoring and maintenance capabilities for ongoing data quality
- **FR15:** Compliance reporting and audit trails for regulatory requirements
- **Data Quality:** Advanced validation ensuring 100% data integrity and organization quality
