# Story 3.4: Migration Monitoring & Control

## Story

As a user,
I want comprehensive monitoring and control capabilities for active migrations,
So that I can intervene when needed, optimize performance in real-time, track detailed analytics, and maintain full visibility into migration operations across multiple concurrent plans.

## Story Context

**Epic:** 3 - Migration Planning and Execution  
**Dependencies:** Story 3.3 (Migration Execution Engine), Story 3.2 (Advanced Organization Rules), Story 2.4 (Task Queue Management UI)  
**Story Type:** Core Feature - Advanced Monitoring & Control  

This story extends the migration execution capabilities with sophisticated monitoring, real-time intervention, performance optimization, and comprehensive analytics. It provides advanced users with the tools to fine-tune migrations, respond to issues proactively, and maintain optimal system performance during complex migration operations.

## Acceptance Criteria

### Real-Time Migration Dashboard
- [ ] **Multi-migration overview:** Monitor multiple concurrent migration plans simultaneously
- [ ] **Live performance metrics:** Real-time transfer speeds, I/O utilization, CPU/memory usage
- [ ] **System health monitoring:** Disk health, temperature, available space, error rates
- [ ] **Resource utilization charts:** Historical and real-time resource usage visualization
- [ ] **Migration timeline:** Visual timeline showing migration phases and milestones
- [ ] **Alert system:** Configurable alerts for performance issues, errors, and completion

### Advanced Progress Analytics
- [ ] **Detailed progress breakdown:** Progress by file type, size categories, directory trees
- [ ] **Transfer rate analysis:** Speed trends, bottlenecks identification, peak performance periods
- [ ] **File-level tracking:** Individual file progress for large files with ETA
- [ ] **Batch performance analysis:** Performance comparison across different batches
- [ ] **Historical comparisons:** Compare current migration against previous similar migrations
- [ ] **Predictive analytics:** Machine learning-based ETA refinement and bottleneck prediction

### Dynamic Performance Control
- [ ] **Resource throttling:** Real-time adjustment of CPU, memory, and I/O limits
- [ ] **Priority rebalancing:** Dynamically adjust task priorities during execution
- [ ] **Concurrent task scaling:** Increase/decrease concurrent tasks based on system performance
- [ ] **Disk scheduling optimization:** Optimize disk access patterns to reduce seek time
- [ ] **Network bandwidth control:** Manage network usage for remote/cloud migrations
- [ ] **Power management integration:** Coordinate with system power management policies

### Migration Intervention Tools
- [ ] **Selective pause/resume:** Pause specific file types, directories, or size categories
- [ ] **Task reordering:** Manually reorder pending tasks based on urgency or dependencies
- [ ] **File skipping:** Skip problematic files and continue with rest of migration
- [ ] **Batch size adjustment:** Dynamically adjust batch sizes based on performance
- [ ] **Route optimization:** Change file routing for better performance
- [ ] **Emergency protocols:** Rapid response tools for critical situations

### Error Management & Recovery
- [ ] **Error pattern analysis:** Identify recurring error patterns and suggest fixes
- [ ] **Intelligent retry strategies:** Adaptive retry logic based on error type and history
- [ ] **Partial recovery options:** Recover specific file ranges or directories
- [ ] **Error correlation:** Link errors to system events, disk health, or resource constraints
- [ ] **Recovery recommendations:** AI-powered suggestions for resolving migration issues
- [ ] **Rollback planning:** Advanced rollback options with selective file restoration

### Performance Optimization
- [ ] **Automatic optimization:** AI-driven optimization suggestions based on migration patterns
- [ ] **Resource balancing:** Automatically balance resources across concurrent migrations
- [ ] **Disk defragmentation integration:** Coordinate with defrag operations for optimal performance
- [ ] **Cache management:** Intelligent caching strategies for frequently accessed files
- [ ] **Compression optimization:** Dynamic compression decisions based on file types and transfer speeds
- [ ] **Parallel processing optimization:** Optimize parallel operations based on hardware capabilities

### Advanced Analytics & Reporting
- [ ] **Migration efficiency scoring:** Score migrations based on speed, resource usage, and success rate
- [ ] **Trend analysis:** Long-term trends in migration performance and patterns
- [ ] **Predictive maintenance:** Predict hardware issues based on migration performance data
- [ ] **Cost analysis:** Analyze resource costs and efficiency metrics
- [ ] **Custom dashboards:** User-configurable dashboards for specific monitoring needs
- [ ] **Export capabilities:** Export analytics data for external analysis tools

## Technical Implementation

### Backend Components

**Migration Monitor Service** (`internal/services/migration_monitor.go`)
```go
type MigrationMonitorService struct {
    db              *database.DB
    executor        *MigrationExecutor
    metricsService  *MetricsService
    alertService    *AlertService
    optimizerService *OptimizationService
    logger          *slog.Logger
    
    // Real-time monitoring state
    activeMonitors  sync.Map // map[executionID]*MonitoringSession
    systemMetrics   *SystemMetrics
    alertRules      []AlertRule
    
    // Performance optimization
    performanceHistory map[string]*PerformanceProfile
    optimizationRules   []OptimizationRule
}

type MonitoringSession struct {
    ExecutionID     string                    `json:"execution_id"`
    PlanID          string                    `json:"plan_id"`
    StartedAt       time.Time                 `json:"started_at"`
    LastUpdate      time.Time                 `json:"last_update"`
    Metrics         *MigrationMetrics         `json:"metrics"`
    Performance     *PerformanceAnalysis      `json:"performance"`
    Alerts          []ActiveAlert             `json:"alerts"`
    Interventions   []InterventionRecord      `json:"interventions"`
    OptimizationLog []OptimizationAction      `json:"optimization_log"`
    mutex           sync.RWMutex
}

type MigrationMetrics struct {
    // Transfer metrics
    TransferRate        RateMetrics          `json:"transfer_rate"`
    IOOperations        IOMetrics            `json:"io_operations"`
    FileOperations      FileOperationMetrics `json:"file_operations"`
    
    // Resource utilization
    CPUUsage            ResourceMetric       `json:"cpu_usage"`
    MemoryUsage         ResourceMetric       `json:"memory_usage"`
    DiskUsage           map[string]DiskMetric `json:"disk_usage"`
    NetworkUsage        NetworkMetric        `json:"network_usage"`
    
    // Error and retry metrics
    ErrorRates          ErrorMetrics         `json:"error_rates"`
    RetryStatistics     RetryMetrics         `json:"retry_statistics"`
    
    // Performance indicators
    EfficiencyScore     float64              `json:"efficiency_score"`
    BottleneckIndicators []BottleneckInfo    `json:"bottleneck_indicators"`
    OptimizationOpportunities []OptimizationOpportunity `json:"optimization_opportunities"`
}

type PerformanceAnalysis struct {
    CurrentThroughput    int64                `json:"current_throughput"`
    AverageThroughput    int64                `json:"average_throughput"`
    PeakThroughput       int64                `json:"peak_throughput"`
    ThroughputTrend      TrendAnalysis        `json:"throughput_trend"`
    
    FileTypePerformance  map[string]FileTypePerf `json:"file_type_performance"`
    SizeBasedPerformance map[string]SizePerf     `json:"size_based_performance"`
    
    PredictedCompletion  time.Time            `json:"predicted_completion"`
    ConfidenceLevel      float64              `json:"confidence_level"`
    
    PerformanceIssues    []PerformanceIssue   `json:"performance_issues"`
    OptimizationSuggestions []OptimizationSuggestion `json:"optimization_suggestions"`
}

func NewMigrationMonitorService(deps ServiceDependencies) *MigrationMonitorService {
    return &MigrationMonitorService{
        db:              deps.DB,
        executor:        deps.Executor,
        metricsService:  deps.MetricsService,
        alertService:    deps.AlertService,
        optimizerService: deps.OptimizerService,
        logger:          deps.Logger.With("service", "migration_monitor"),
        performanceHistory: make(map[string]*PerformanceProfile),
        systemMetrics:   NewSystemMetrics(),
    }
}

// StartMonitoring begins monitoring an active migration execution
func (s *MigrationMonitorService) StartMonitoring(ctx context.Context, executionID string) (*MonitoringSession, error) {
    execCtx, err := s.executor.GetExecutionContext(executionID)
    if err != nil {
        return nil, fmt.Errorf("failed to get execution context: %w", err)
    }
    
    session := &MonitoringSession{
        ExecutionID:     executionID,
        PlanID:          execCtx.PlanID,
        StartedAt:       time.Now(),
        LastUpdate:      time.Now(),
        Metrics:         NewMigrationMetrics(),
        Performance:     NewPerformanceAnalysis(),
        Alerts:          []ActiveAlert{},
        Interventions:   []InterventionRecord{},
        OptimizationLog: []OptimizationAction{},
    }
    
    // Store monitoring session
    s.activeMonitors.Store(executionID, session)
    
    // Start background monitoring goroutine
    go s.monitorExecution(ctx, session)
    
    s.logger.Info("Started monitoring migration execution", "execution_id", executionID, "plan_id", execCtx.PlanID)
    return session, nil
}

// monitorExecution runs the main monitoring loop
func (s *MigrationMonitorService) monitorExecution(ctx context.Context, session *MonitoringSession) {
    ticker := time.NewTicker(5 * time.Second) // Update every 5 seconds
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            if err := s.updateMonitoringSession(ctx, session); err != nil {
                s.logger.Error("Failed to update monitoring session", "execution_id", session.ExecutionID, "error", err)
            }
            
            // Check if execution is complete
            execCtx, err := s.executor.GetExecutionContext(session.ExecutionID)
            if err != nil {
                s.logger.Error("Failed to get execution context during monitoring", "execution_id", session.ExecutionID, "error", err)
                return
            }
            
            if execCtx.Status == ExecutionStatusCompleted || 
               execCtx.Status == ExecutionStatusFailed || 
               execCtx.Status == ExecutionStatusCancelled {
                s.finalizeMonitoringSession(ctx, session)
                return
            }
        }
    }
}

func (s *MigrationMonitorService) updateMonitoringSession(ctx context.Context, session *MonitoringSession) error {
    session.mutex.Lock()
    defer session.mutex.Unlock()
    
    // Update execution context
    execCtx, err := s.executor.GetExecutionContext(session.ExecutionID)
    if err != nil {
        return fmt.Errorf("failed to get execution context: %w", err)
    }
    
    // Collect system metrics
    systemMetrics, err := s.systemMetrics.Collect()
    if err != nil {
        s.logger.Warn("Failed to collect system metrics", "error", err)
    }
    
    // Update migration metrics
    s.updateMigrationMetrics(session, execCtx, systemMetrics)
    
    // Update performance analysis
    s.updatePerformanceAnalysis(session, execCtx, systemMetrics)
    
    // Check alert conditions
    s.checkAlertConditions(session)
    
    // Apply automatic optimizations
    s.applyAutomaticOptimizations(ctx, session)
    
    // Update timestamp
    session.LastUpdate = time.Now()
    
    return nil
}

func (s *MigrationMonitorService) updateMigrationMetrics(session *MonitoringSession, execCtx *ExecutionContext, sysMetrics *SystemMetrics) {
    // Update transfer rate metrics
    session.Metrics.TransferRate = s.calculateTransferRates(execCtx, session.Metrics.TransferRate)
    
    // Update I/O metrics
    session.Metrics.IOOperations = s.calculateIOMetrics(execCtx, sysMetrics)
    
    // Update file operation metrics
    session.Metrics.FileOperations = s.calculateFileOperationMetrics(execCtx)
    
    // Update resource utilization
    session.Metrics.CPUUsage = sysMetrics.CPU
    session.Metrics.MemoryUsage = sysMetrics.Memory
    session.Metrics.DiskUsage = sysMetrics.Disks
    session.Metrics.NetworkUsage = sysMetrics.Network
    
    // Update error metrics
    session.Metrics.ErrorRates = s.calculateErrorRates(execCtx)
    
    // Calculate efficiency score
    session.Metrics.EfficiencyScore = s.calculateEfficiencyScore(session.Metrics)
    
    // Identify bottlenecks
    session.Metrics.BottleneckIndicators = s.identifyBottlenecks(session.Metrics, sysMetrics)
    
    // Find optimization opportunities
    session.Metrics.OptimizationOpportunities = s.findOptimizationOpportunities(session.Metrics)
}

func (s *MigrationMonitorService) updatePerformanceAnalysis(session *MonitoringSession, execCtx *ExecutionContext, sysMetrics *SystemMetrics) {
    // Calculate current throughput
    session.Performance.CurrentThroughput = s.calculateCurrentThroughput(execCtx)
    
    // Update average and peak throughput
    session.Performance = s.updateThroughputStatistics(session.Performance, session.Performance.CurrentThroughput)
    
    // Analyze performance by file type and size
    session.Performance.FileTypePerformance = s.analyzeFileTypePerformance(execCtx)
    session.Performance.SizeBasedPerformance = s.analyzeSizeBasedPerformance(execCtx)
    
    // Update predicted completion time
    session.Performance.PredictedCompletion, session.Performance.ConfidenceLevel = s.predictCompletionTime(execCtx, session.Performance)
    
    // Identify performance issues
    session.Performance.PerformanceIssues = s.identifyPerformanceIssues(session.Metrics, session.Performance)
    
    // Generate optimization suggestions
    session.Performance.OptimizationSuggestions = s.generateOptimizationSuggestions(session)
}

// ApplyIntervention applies a real-time intervention to a migration
func (s *MigrationMonitorService) ApplyIntervention(ctx context.Context, executionID string, intervention Intervention) error {
    session, ok := s.activeMonitors.Load(executionID)
    if !ok {
        return fmt.Errorf("no active monitoring session for execution %s", executionID)
    }
    
    monitorSession := session.(*MonitoringSession)
    
    switch intervention.Type {
    case InterventionTypeResourceThrottling:
        return s.applyResourceThrottling(ctx, executionID, intervention)
    case InterventionTypePriorityAdjustment:
        return s.applyPriorityAdjustment(ctx, executionID, intervention)
    case InterventionTypeTaskReordering:
        return s.applyTaskReordering(ctx, executionID, intervention)
    case InterventionTypeSelectivePause:
        return s.applySelectivePause(ctx, executionID, intervention)
    case InterventionTypeBatchSizeAdjustment:
        return s.applyBatchSizeAdjustment(ctx, executionID, intervention)
    default:
        return fmt.Errorf("unknown intervention type: %s", intervention.Type)
    }
}

func (s *MigrationMonitorService) applyResourceThrottling(ctx context.Context, executionID string, intervention Intervention) error {
    limits, ok := intervention.Parameters["resource_limits"].(ResourceLimits)
    if !ok {
        return fmt.Errorf("invalid resource limits in intervention")
    }
    
    // Apply CPU throttling
    if limits.MaxCPUPercent > 0 {
        if err := s.executor.SetCPULimit(ctx, executionID, limits.MaxCPUPercent); err != nil {
            return fmt.Errorf("failed to set CPU limit: %w", err)
        }
    }
    
    // Apply memory limits
    if limits.MaxMemoryMB > 0 {
        if err := s.executor.SetMemoryLimit(ctx, executionID, limits.MaxMemoryMB); err != nil {
            return fmt.Errorf("failed to set memory limit: %w", err)
        }
    }
    
    // Apply I/O throttling
    if limits.MaxIOBytesPerSec > 0 {
        if err := s.executor.SetIOLimit(ctx, executionID, limits.MaxIOBytesPerSec); err != nil {
            return fmt.Errorf("failed to set I/O limit: %w", err)
        }
    }
    
    // Record intervention
    s.recordIntervention(executionID, intervention)
    
    s.logger.Info("Applied resource throttling intervention", "execution_id", executionID, "limits", limits)
    return nil
}

func (s *MigrationMonitorService) applyPriorityAdjustment(ctx context.Context, executionID string, intervention Intervention) error {
    taskIDs, ok := intervention.Parameters["task_ids"].([]string)
    if !ok {
        return fmt.Errorf("invalid task IDs in intervention")
    }
    
    newPriority, ok := intervention.Parameters["priority"].(string)
    if !ok {
        return fmt.Errorf("invalid priority in intervention")
    }
    
    // Adjust priority for specified tasks
    for _, taskID := range taskIDs {
        if err := s.executor.SetTaskPriority(ctx, taskID, newPriority); err != nil {
            s.logger.Error("Failed to adjust task priority", "task_id", taskID, "priority", newPriority, "error", err)
        }
    }
    
    // Record intervention
    s.recordIntervention(executionID, intervention)
    
    s.logger.Info("Applied priority adjustment intervention", "execution_id", executionID, "tasks", len(taskIDs), "priority", newPriority)
    return nil
}

// OptimizationEngine applies automatic optimizations
type OptimizationEngine struct {
    monitor     *MigrationMonitorService
    rules       []OptimizationRule
    ml          *MLPredictor // Machine learning component for advanced predictions
    logger      *slog.Logger
}

func (e *OptimizationEngine) AnalyzeAndOptimize(ctx context.Context, session *MonitoringSession) []OptimizationAction {
    var actions []OptimizationAction
    
    // Analyze current performance
    perfAnalysis := e.analyzeCurrentPerformance(session)
    
    // Apply rule-based optimizations
    ruleActions := e.applyOptimizationRules(session, perfAnalysis)
    actions = append(actions, ruleActions...)
    
    // Apply ML-based optimizations
    if e.ml != nil {
        mlActions := e.ml.PredictOptimizations(session, perfAnalysis)
        actions = append(actions, mlActions...)
    }
    
    // Execute approved optimizations
    for _, action := range actions {
        if action.AutoApproved {
            if err := e.executeOptimizationAction(ctx, session.ExecutionID, action); err != nil {
                e.logger.Error("Failed to execute optimization action", "action", action.Type, "error", err)
            }
        }
    }
    
    return actions
}

func (e *OptimizationEngine) executeOptimizationAction(ctx context.Context, executionID string, action OptimizationAction) error {
    switch action.Type {
    case OptimizationTypeConcurrencyAdjustment:
        concurrency, ok := action.Parameters["concurrency"].(int)
        if !ok {
            return fmt.Errorf("invalid concurrency parameter")
        }
        return e.monitor.executor.SetConcurrency(ctx, executionID, concurrency)
        
    case OptimizationTypeBatchSizeAdjustment:
        batchSize, ok := action.Parameters["batch_size"].(int)
        if !ok {
            return fmt.Errorf("invalid batch size parameter")
        }
        return e.monitor.executor.SetBatchSize(ctx, executionID, batchSize)
        
    case OptimizationTypeIOPatternOptimization:
        pattern, ok := action.Parameters["io_pattern"].(string)
        if !ok {
            return fmt.Errorf("invalid I/O pattern parameter")
        }
        return e.monitor.executor.SetIOPattern(ctx, executionID, pattern)
        
    case OptimizationTypeCompressionToggle:
        enableCompression, ok := action.Parameters["enable_compression"].(bool)
        if !ok {
            return fmt.Errorf("invalid compression parameter")
        }
        return e.monitor.executor.SetCompressionEnabled(ctx, executionID, enableCompression)
        
    default:
        return fmt.Errorf("unknown optimization type: %s", action.Type)
    }
}
```

**Alert Management System** (`internal/services/alert_service.go`)
```go
type AlertService struct {
    db          *database.DB
    monitor     *MigrationMonitorService
    notifier    *NotificationService
    logger      *slog.Logger
    alertRules  []AlertRule
    activeAlerts sync.Map // map[executionID][]ActiveAlert
}

type AlertRule struct {
    ID          string               `json:"id"`
    Name        string               `json:"name"`
    Description string               `json:"description"`
    Condition   AlertCondition       `json:"condition"`
    Severity    AlertSeverity        `json:"severity"`
    Actions     []AlertAction        `json:"actions"`
    Enabled     bool                 `json:"enabled"`
    Cooldown    time.Duration        `json:"cooldown"`
    CreatedOn   time.Time            `json:"created_on"`
}

type AlertCondition struct {
    MetricType     string        `json:"metric_type"`     // transfer_rate, error_rate, cpu_usage, etc.
    Operator       string        `json:"operator"`        // greater_than, less_than, equals
    Threshold      float64       `json:"threshold"`
    Duration       time.Duration `json:"duration"`        // Condition must persist for this duration
    AggregationFunc string       `json:"aggregation_func"` // avg, max, min, sum
}

type ActiveAlert struct {
    ID           string        `json:"id"`
    RuleID       string        `json:"rule_id"`
    ExecutionID  string        `json:"execution_id"`
    Severity     AlertSeverity `json:"severity"`
    Message      string        `json:"message"`
    TriggeredAt  time.Time     `json:"triggered_at"`
    LastUpdate   time.Time     `json:"last_update"`
    Acknowledged bool          `json:"acknowledged"`
    ResolvedAt   *time.Time    `json:"resolved_at,omitempty"`
    Context      AlertContext  `json:"context"`
}

func (s *AlertService) EvaluateAlerts(executionID string, metrics *MigrationMetrics) {
    for _, rule := range s.alertRules {
        if !rule.Enabled {
            continue
        }
        
        // Check if alert condition is met
        conditionMet := s.evaluateCondition(rule.Condition, metrics)
        
        // Get existing alert for this rule and execution
        alertKey := fmt.Sprintf("%s_%s", executionID, rule.ID)
        existingAlert, hasAlert := s.getActiveAlert(alertKey)
        
        if conditionMet {
            if !hasAlert {
                // Create new alert
                alert := ActiveAlert{
                    ID:          generateAlertID(),
                    RuleID:      rule.ID,
                    ExecutionID: executionID,
                    Severity:    rule.Severity,
                    Message:     s.generateAlertMessage(rule, metrics),
                    TriggeredAt: time.Now(),
                    LastUpdate:  time.Now(),
                    Context:     s.buildAlertContext(rule, metrics),
                }
                
                s.activeAlerts.Store(alertKey, alert)
                s.triggerAlertActions(alert, rule.Actions)
                
                s.logger.Warn("Alert triggered", "rule", rule.Name, "execution_id", executionID, "severity", rule.Severity)
            } else {
                // Update existing alert
                existingAlert.LastUpdate = time.Now()
                existingAlert.Context = s.buildAlertContext(rule, metrics)
                s.activeAlerts.Store(alertKey, existingAlert)
            }
        } else if hasAlert && existingAlert.ResolvedAt == nil {
            // Resolve alert
            now := time.Now()
            existingAlert.ResolvedAt = &now
            existingAlert.LastUpdate = now
            s.activeAlerts.Store(alertKey, existingAlert)
            
            s.logger.Info("Alert resolved", "rule", rule.Name, "execution_id", executionID)
        }
    }
}

func (s *AlertService) triggerAlertActions(alert ActiveAlert, actions []AlertAction) {
    for _, action := range actions {
        switch action.Type {
        case AlertActionTypeNotification:
            s.notifier.SendAlert(alert, action.Parameters)
        case AlertActionTypePauseExecution:
            s.monitor.executor.PauseExecution(context.Background(), alert.ExecutionID)
        case AlertActionTypeResourceThrottling:
            intervention := Intervention{
                Type:       InterventionTypeResourceThrottling,
                Parameters: action.Parameters,
                AutoApplied: true,
            }
            s.monitor.ApplyIntervention(context.Background(), alert.ExecutionID, intervention)
        case AlertActionTypeEmailNotification:
            s.notifier.SendEmailAlert(alert, action.Parameters)
        }
    }
}
```

### API Endpoints

**Migration Monitoring API** (`internal/api/migration_monitoring.go`)
```go
// GET /api/v1/migration-monitoring/dashboard
func (h *MigrationMonitoringHandler) GetDashboard(c *gin.Context) {
    // Get all active monitoring sessions
    sessions := h.monitor.GetActiveSessions()
    
    // Get system-wide metrics
    systemMetrics, err := h.monitor.GetSystemMetrics()
    if err != nil {
        h.logger.Error("Failed to get system metrics", "error", err)
        c.JSON(500, gin.H{"error": "Failed to get system metrics"})
        return
    }
    
    // Build dashboard data
    dashboard := MigrationDashboard{
        ActiveMigrations:    len(sessions),
        SystemMetrics:      systemMetrics,
        MonitoringSessions: sessions,
        AlertSummary:       h.alertService.GetAlertSummary(),
        PerformanceOverview: h.monitor.GetPerformanceOverview(),
    }
    
    c.JSON(200, dashboard)
}

// GET /api/v1/migration-monitoring/:id
func (h *MigrationMonitoringHandler) GetMonitoringSession(c *gin.Context) {
    executionID := c.Param("id")
    
    session, err := h.monitor.GetMonitoringSession(executionID)
    if err != nil {
        if errors.Is(err, ErrMonitoringSessionNotFound) {
            c.JSON(404, gin.H{"error": "Monitoring session not found"})
            return
        }
        h.logger.Error("Failed to get monitoring session", "execution_id", executionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to get monitoring session"})
        return
    }
    
    c.JSON(200, session)
}

// POST /api/v1/migration-monitoring/:id/interventions
func (h *MigrationMonitoringHandler) ApplyIntervention(c *gin.Context) {
    executionID := c.Param("id")
    
    var req ApplyInterventionRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": "Invalid request body", "details": err.Error()})
        return
    }
    
    intervention := Intervention{
        Type:        req.Type,
        Parameters:  req.Parameters,
        Reason:      req.Reason,
        AppliedBy:   req.UserID,
        AppliedAt:   time.Now(),
        AutoApplied: false,
    }
    
    if err := h.monitor.ApplyIntervention(c.Request.Context(), executionID, intervention); err != nil {
        h.logger.Error("Failed to apply intervention", "execution_id", executionID, "type", req.Type, "error", err)
        c.JSON(500, gin.H{"error": "Failed to apply intervention", "details": err.Error()})
        return
    }
    
    c.JSON(200, gin.H{"message": "Intervention applied successfully", "intervention_id": intervention.ID})
}

// GET /api/v1/migration-monitoring/:id/performance-analysis
func (h *MigrationMonitoringHandler) GetPerformanceAnalysis(c *gin.Context) {
    executionID := c.Param("id")
    timeRange := c.Query("time_range") // e.g., "1h", "6h", "24h"
    
    analysis, err := h.monitor.GetPerformanceAnalysis(executionID, timeRange)
    if err != nil {
        h.logger.Error("Failed to get performance analysis", "execution_id", executionID, "error", err)
        c.JSON(500, gin.H{"error": "Failed to get performance analysis"})
        return
    }
    
    c.JSON(200, analysis)
}

// WebSocket endpoint for real-time monitoring updates
// GET /api/v1/migration-monitoring/:id/stream
func (h *MigrationMonitoringHandler) StreamMonitoring(c *gin.Context) {
    executionID := c.Param("id")
    
    // Upgrade to WebSocket connection
    conn, err := h.wsUpgrader.Upgrade(c.Writer, c.Request, nil)
    if err != nil {
        h.logger.Error("Failed to upgrade to WebSocket", "error", err)
        return
    }
    defer conn.Close()
    
    // Start streaming monitoring data
    ctx, cancel := context.WithCancel(c.Request.Context())
    defer cancel()
    
    h.streamMonitoringData(ctx, conn, executionID)
}

func (h *MigrationMonitoringHandler) streamMonitoringData(ctx context.Context, conn *websocket.Conn, executionID string) {
    ticker := time.NewTicker(2 * time.Second)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            session, err := h.monitor.GetMonitoringSession(executionID)
            if err != nil {
                continue
            }
            
            update := MonitoringUpdate{
                ExecutionID: executionID,
                Timestamp:   time.Now(),
                Metrics:     session.Metrics,
                Performance: session.Performance,
                Alerts:      session.Alerts,
            }
            
            if err := conn.WriteJSON(update); err != nil {
                h.logger.Error("Failed to send monitoring update", "execution_id", executionID, "error", err)
                return
            }
        }
    }
}

// POST /api/v1/migration-monitoring/alerts/rules
func (h *MigrationMonitoringHandler) CreateAlertRule(c *gin.Context) {
    var req CreateAlertRuleRequest
    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": "Invalid request body", "details": err.Error()})
        return
    }
    
    rule := AlertRule{
        ID:          generateAlertRuleID(),
        Name:        req.Name,
        Description: req.Description,
        Condition:   req.Condition,
        Severity:    req.Severity,
        Actions:     req.Actions,
        Enabled:     req.Enabled,
        Cooldown:    req.Cooldown,
        CreatedOn:   time.Now(),
    }
    
    if err := h.alertService.CreateAlertRule(rule); err != nil {
        h.logger.Error("Failed to create alert rule", "name", req.Name, "error", err)
        c.JSON(500, gin.H{"error": "Failed to create alert rule"})
        return
    }
    
    c.JSON(201, rule)
}
```

### Frontend Components

**Migration Monitoring Dashboard** (`app/migration/monitoring/page.tsx`)
```tsx
'use client'
export default function MigrationMonitoringPage() {
  const { dashboard, isLoading, refetch } = useMigrationDashboard()
  const [selectedExecution, setSelectedExecution] = useState<string | null>(null)
  const [alertsOpen, setAlertsOpen] = useState(false)
  
  return (
    <div className="migration-monitoring-container">
      <div className="dashboard-header">
        <h1>Migration Monitoring Dashboard</h1>
        <div className="header-controls">
          <Button 
            variant="outline" 
            onClick={() => setAlertsOpen(true)}
            className="alerts-button"
          >
            <Bell className="w-4 h-4 mr-2" />
            Alerts {dashboard?.alertSummary.active > 0 && `(${dashboard.alertSummary.active})`}
          </Button>
          <Button onClick={refetch}>
            <RefreshCw className="w-4 h-4 mr-2" />
            Refresh
          </Button>
        </div>
      </div>
      
      {isLoading ? (
        <DashboardLoadingSkeleton />
      ) : (
        <div className="dashboard-content">
          <div className="dashboard-overview">
            <SystemMetricsOverview metrics={dashboard.systemMetrics} />
            <ActiveMigrationsOverview migrations={dashboard.monitoringSessions} />
            <PerformanceOverview data={dashboard.performanceOverview} />
          </div>
          
          <div className="active-migrations-section">
            <h2>Active Migrations</h2>
            <MigrationsList 
              sessions={dashboard.monitoringSessions}
              onSelectMigration={setSelectedExecution}
            />
          </div>
          
          {selectedExecution && (
            <MigrationDetailPanel 
              executionId={selectedExecution}
              onClose={() => setSelectedExecution(null)}
            />
          )}
        </div>
      )}
      
      <AlertsPanel 
        isOpen={alertsOpen}
        onClose={() => setAlertsOpen(false)}
      />
    </div>
  )
}
```

**Real-Time Monitoring Component** (`components/migration/RealtimeMonitoring.tsx`)
```tsx
export function RealtimeMonitoring({ executionId }: { executionId: string }) {
  const { session, metrics, isConnected } = useRealtimeMonitoring(executionId)
  const [interventionDialogOpen, setInterventionDialogOpen] = useState(false)
  const [selectedChart, setSelectedChart] = useState<string>('throughput')
  
  return (
    <div className="realtime-monitoring">
      <div className="monitoring-header">
        <div className="connection-status">
          <div className={`status-indicator ${isConnected ? 'connected' : 'disconnected'}`} />
          <span>{isConnected ? 'Connected' : 'Disconnected'}</span>
        </div>
        <Button 
          onClick={() => setInterventionDialogOpen(true)}
          variant="outline"
        >
          <Settings className="w-4 h-4 mr-2" />
          Intervene
        </Button>
      </div>
      
      <div className="monitoring-grid">
        <div className="metrics-cards">
          <MetricCard
            title="Current Throughput"
            value={formatBytes(metrics?.currentThroughput || 0) + '/s'}
            trend={metrics?.throughputTrend}
            icon={Zap}
          />
          <MetricCard
            title="Efficiency Score"
            value={`${(metrics?.efficiencyScore || 0).toFixed(1)}%`}
            trend={metrics?.efficiencyTrend}
            icon={TrendingUp}
          />
          <MetricCard
            title="Active Alerts"
            value={session?.alerts.length || 0}
            severity={session?.alerts.some(a => a.severity === 'critical') ? 'error' : 'normal'}
            icon={AlertTriangle}
          />
          <MetricCard
            title="Resource Usage"
            value={`${(metrics?.cpuUsage || 0).toFixed(1)}% CPU`}
            subValue={`${formatBytes(metrics?.memoryUsage || 0)} RAM`}
            icon={Cpu}
          />
        </div>
        
        <div className="performance-charts">
          <div className="chart-selector">
            <Select value={selectedChart} onValueChange={setSelectedChart}>
              <SelectTrigger>
                <SelectValue />
              </SelectTrigger>
              <SelectContent>
                <SelectItem value="throughput">Throughput</SelectItem>
                <SelectItem value="resources">Resource Usage</SelectItem>
                <SelectItem value="errors">Error Rate</SelectItem>
                <SelectItem value="io">I/O Operations</SelectItem>
              </SelectContent>
            </Select>
          </div>
          
          <div className="chart-container">
            {selectedChart === 'throughput' && <ThroughputChart data={metrics?.throughputHistory} />}
            {selectedChart === 'resources' && <ResourceUsageChart data={metrics?.resourceHistory} />}
            {selectedChart === 'errors' && <ErrorRateChart data={metrics?.errorHistory} />}
            {selectedChart === 'io' && <IOOperationsChart data={metrics?.ioHistory} />}
          </div>
        </div>
        
        <div className="bottleneck-analysis">
          <h3>Performance Analysis</h3>
          <BottleneckIndicators indicators={metrics?.bottleneckIndicators || []} />
          <OptimizationSuggestions suggestions={metrics?.optimizationOpportunities || []} />
        </div>
      </div>
      
      <InterventionDialog
        isOpen={interventionDialogOpen}
        onClose={() => setInterventionDialogOpen(false)}
        executionId={executionId}
        currentMetrics={metrics}
      />
    </div>
  )
}
```

**Intervention Control Panel** (`components/migration/InterventionPanel.tsx`)
```tsx
export function InterventionPanel({ executionId, currentMetrics }: InterventionPanelProps) {
  const [interventionType, setInterventionType] = useState<InterventionType>('resource_throttling')
  const [parameters, setParameters] = useState<Record<string, any>>({})
  const { applyIntervention, isApplying } = useInterventions()
  
  const handleApplyIntervention = async () => {
    const intervention: Intervention = {
      type: interventionType,
      parameters: parameters,
      reason: parameters.reason || 'Manual intervention',
      appliedBy: 'user', // Would come from auth context
      appliedAt: new Date(),
      autoApplied: false
    }
    
    await applyIntervention(executionId, intervention)
  }
  
  return (
    <div className="intervention-panel">
      <div className="intervention-type-selector">
        <Label>Intervention Type</Label>
        <Select value={interventionType} onValueChange={setInterventionType}>
          <SelectTrigger>
            <SelectValue />
          </SelectTrigger>
          <SelectContent>
            <SelectItem value="resource_throttling">Resource Throttling</SelectItem>
            <SelectItem value="priority_adjustment">Priority Adjustment</SelectItem>
            <SelectItem value="task_reordering">Task Reordering</SelectItem>
            <SelectItem value="selective_pause">Selective Pause</SelectItem>
            <SelectItem value="batch_size_adjustment">Batch Size Adjustment</SelectItem>
          </SelectContent>
        </Select>
      </div>
      
      <div className="intervention-parameters">
        {interventionType === 'resource_throttling' && (
          <ResourceThrottlingControls 
            currentUsage={currentMetrics}
            parameters={parameters}
            onChange={setParameters}
          />
        )}
        
        {interventionType === 'priority_adjustment' && (
          <PriorityAdjustmentControls 
            executionId={executionId}
            parameters={parameters}
            onChange={setParameters}
          />
        )}
        
        {interventionType === 'selective_pause' && (
          <SelectivePauseControls 
            parameters={parameters}
            onChange={setParameters}
          />
        )}
        
        {interventionType === 'batch_size_adjustment' && (
          <BatchSizeControls 
            currentBatchSize={currentMetrics?.currentBatchSize}
            parameters={parameters}
            onChange={setParameters}
          />
        )}
      </div>
      
      <div className="intervention-actions">
        <Button 
          onClick={handleApplyIntervention}
          disabled={isApplying}
          className="apply-intervention-button"
        >
          {isApplying && <Loader2 className="w-4 h-4 mr-2 animate-spin" />}
          Apply Intervention
        </Button>
      </div>
    </div>
  )
}
```

## Database Schema

**Migration Monitoring Tables** (`migrations/011_migration_monitoring.sql`)
```sql
CREATE TABLE monitoring_sessions (
    execution_id TEXT PRIMARY KEY REFERENCES migration_executions(execution_id) ON DELETE CASCADE,
    plan_id TEXT NOT NULL,
    started_at INTEGER NOT NULL,
    last_update INTEGER NOT NULL,
    metrics TEXT NOT NULL,        -- JSON MigrationMetrics
    performance TEXT NOT NULL,    -- JSON PerformanceAnalysis
    interventions TEXT NOT NULL,  -- JSON array of InterventionRecord
    optimization_log TEXT NOT NULL -- JSON array of OptimizationAction
);

CREATE TABLE alert_rules (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    description TEXT,
    condition TEXT NOT NULL,      -- JSON AlertCondition
    severity TEXT NOT NULL CHECK (severity IN ('info', 'warning', 'error', 'critical')),
    actions TEXT NOT NULL,        -- JSON array of AlertAction
    enabled BOOLEAN NOT NULL DEFAULT true,
    cooldown INTEGER NOT NULL DEFAULT 300, -- seconds
    created_on INTEGER NOT NULL
);

CREATE TABLE active_alerts (
    id TEXT PRIMARY KEY,
    rule_id TEXT NOT NULL REFERENCES alert_rules(id) ON DELETE CASCADE,
    execution_id TEXT NOT NULL,
    severity TEXT NOT NULL,
    message TEXT NOT NULL,
    triggered_at INTEGER NOT NULL,
    last_update INTEGER NOT NULL,
    acknowledged BOOLEAN NOT NULL DEFAULT false,
    resolved_at INTEGER,
    context TEXT NOT NULL         -- JSON AlertContext
);

CREATE INDEX idx_active_alerts_execution_id ON active_alerts(execution_id);
CREATE INDEX idx_active_alerts_severity ON active_alerts(severity);
CREATE INDEX idx_active_alerts_resolved ON active_alerts(resolved_at);

CREATE TABLE intervention_history (
    id TEXT PRIMARY KEY,
    execution_id TEXT NOT NULL,
    type TEXT NOT NULL,
    parameters TEXT NOT NULL,     -- JSON intervention parameters
    applied_by TEXT NOT NULL,
    applied_at INTEGER NOT NULL,
    auto_applied BOOLEAN NOT NULL DEFAULT false,
    result TEXT,                  -- JSON intervention result
    reverted_at INTEGER
);

CREATE INDEX idx_intervention_history_execution_id ON intervention_history(execution_id);
CREATE INDEX idx_intervention_history_applied_at ON intervention_history(applied_at);
```

## Validation & Testing

### Monitoring System Tests
- [ ] Real-time metrics collection and accuracy
- [ ] WebSocket connection stability and performance
- [ ] Alert rule evaluation and triggering
- [ ] Intervention application and effectiveness
- [ ] Performance analysis accuracy

### Integration Tests
- [ ] Integration with migration execution engine
- [ ] Database operations for monitoring data
- [ ] API endpoint functionality
- [ ] Frontend real-time updates
- [ ] Alert notification delivery

### Performance Tests
- [ ] Monitoring overhead during migrations
- [ ] WebSocket performance with multiple connections
- [ ] Database query performance for historical data
- [ ] Chart rendering performance with large datasets
- [ ] Memory usage during long-running monitoring

## Dependencies

**Required Stories:**
- Story 3.3: Migration Execution Engine
- Story 3.2: Advanced Organization Rules
- Story 2.4: Task Queue Management UI
- Epic 2 Complete: Task Engine, MD5, MediaInfo, UI, Opportunistic Logic

**Technical Dependencies:**
- WebSocket support for real-time updates
- Metrics collection and aggregation system
- Alert and notification infrastructure
- Chart visualization libraries
- Machine learning components (optional)

## Definition of Done

- [ ] Real-time migration monitoring dashboard with multiple concurrent migrations
- [ ] Advanced progress analytics with file-type and performance breakdowns
- [ ] Dynamic performance control with resource throttling and optimization
- [ ] Migration intervention tools for real-time adjustments
- [ ] Comprehensive error management and intelligent recovery
- [ ] Performance optimization engine with automatic adjustments
- [ ] Alert system with configurable rules and actions
- [ ] WebSocket-based real-time updates for all monitoring data
- [ ] Complete API endpoints for monitoring and control
- [ ] Frontend components for dashboard and intervention controls
- [ ] Database schema for monitoring data and alert management

## Success Metrics

- **Monitoring Accuracy:** 99.9%+ accurate real-time metrics collection
- **Response Time:** Sub-second response time for monitoring updates
- **Intervention Effectiveness:** 95%+ successful intervention applications
- **Alert Precision:** Less than 1% false positive alert rate
- **Performance Impact:** Less than 5% monitoring overhead on migration performance
- **User Adoption:** Advanced users utilize 3+ intervention types on average

## Next Stories

This story enables:
- **Story 3.5:** Post-Migration Validation (comprehensive validation using monitoring data)
- **Story 4.1:** External Services Integration (monitoring cloud/network transfers)
- **Story 4.2:** Advanced Reporting & Analytics (long-term analytics based on monitoring data)

## PRD Requirements Fulfilled

- **FR6:** Advanced progress tracking and real-time analytics
- **FR10:** Comprehensive monitoring dashboard with detailed metrics
- **Performance Optimization:** Real-time performance monitoring and optimization
- **Error Management:** Advanced error detection, analysis, and recovery
- **User Control:** Real-time intervention capabilities for power users
- **System Health:** Comprehensive system monitoring during migrations
